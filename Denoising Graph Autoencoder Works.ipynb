{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f93bfe62-bb87-411d-8a30-868f86f1f706",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# 4/19 for checking that the denoising graph autoencoder model works! \n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch_geometric.data import Data, DataLoader  # PyG Data and loader\n",
    "from torch.optim import Adam, SGD\n",
    "import matplotlib.pyplot as plt \n",
    "\n",
    "from collections import defaultdict\n",
    "import numpy.ma as ma\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4287583d-11f5-47b4-96c3-d57d223aa1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downsampled MNIST tensor shape: torch.Size([14, 14])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define the transform to downsample the images to 14x14 pixels\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((14, 14)),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset with the downsampling transform\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# # Create data loaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "test_features, test_labels = next(iter(test_loader))\n",
    "true = test_features[0].squeeze()\n",
    "plt.imshow(true, cmap=\"gray\")\n",
    "print(f\"Downsampled MNIST tensor shape: {true.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc95265f-0275-446b-ab7a-971c5721997a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MNIST classifier MLP class for dataset\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, init_type='xavier', seed=None):\n",
    "        super(MLP, self).__init__()\n",
    "        self.fc1 = nn.Linear(196, 32)\n",
    "        self.fc2 = nn.Linear(32, 32)\n",
    "        self.fc3 = nn.Linear(32, 10)\n",
    "        \n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)  # Set a unique seed for reproducibility\n",
    "\n",
    "        self.init_weights(init_type)\n",
    "\n",
    "    def init_weights(self, init_type):\n",
    "        if init_type == 'xavier':\n",
    "            nn.init.xavier_uniform_(self.fc1.weight)\n",
    "            nn.init.xavier_uniform_(self.fc2.weight)\n",
    "            nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        elif init_type == 'he':\n",
    "            nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc3.weight, nonlinearity='relu')\n",
    "        else:\n",
    "            nn.init.normal_(self.fc1.weight)\n",
    "            nn.init.normal_(self.fc2.weight)\n",
    "            nn.init.normal_(self.fc3.weight)\n",
    "        \n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "        nn.init.zeros_(self.fc3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 196)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "def test_mlp(model, test_loader, device = device):\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # No need to compute gradients for evaluation\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    \n",
    "    accuracy = 100 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "def train_mlp(model, epochs=3):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = Adam(model.parameters(), lr=1e-3)\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "94e47948-d8ca-4378-afe0-a1cbcd27a14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.data import Data\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.nn import GCNConv, BatchNorm, JumpingKnowledge, GraphNorm, GATConv, GAT\n",
    "import time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bfcd98-e582-4290-9509-e076313cc9c4",
   "metadata": {},
   "source": [
    "# Git Rebasin Stuff: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "902e26b5-a400-4a6a-8088-2c344fc6d197",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for permutations and weight matching\n",
    "def permute_layer_weights(layer, perm):\n",
    "    \"\"\"Permutes weights and biases of a layer based on the given permutation matrix.\"\"\"\n",
    "    weight = layer.weight.data.clone()\n",
    "    bias = layer.bias.data.clone()\n",
    "\n",
    "    # Permute rows of weights (output dimension)\n",
    "    layer.weight.data = weight[perm, :]\n",
    "\n",
    "    # Permute bias (output dimension)\n",
    "    layer.bias.data = bias[perm]\n",
    "    return layer\n",
    "\n",
    "def permute_model(model, permutations):\n",
    "    \"\"\"Applies a list of permutations to a model's layers.\"\"\"\n",
    "    permute_layer_weights(model.fc1, permutations[0])\n",
    "    permute_layer_weights(model.fc2, permutations[1])\n",
    "\n",
    "    # Adjust input weights of the second hidden layer\n",
    "    model.fc2.weight.data = model.fc2.weight.data[:, permutations[0]]\n",
    "    # Adjust input weights of the output layer\n",
    "    model.fc3.weight.data = model.fc3.weight.data[:, permutations[1]]\n",
    "    return model\n",
    "\n",
    "# Functions to permute weights and adjust input weights\n",
    "def apply_permutation(layer, perm):\n",
    "    \"\"\"\n",
    "    Applies the given permutation to the weights and biases of a layer.\n",
    "    Args:\n",
    "        layer: The layer to permute.\n",
    "        perm: The permutation array.\n",
    "    \"\"\"\n",
    "    # Permute rows (output dimension) of weights\n",
    "    layer.weight.data = layer.weight.data[perm, :]\n",
    "    # Permute biases\n",
    "    layer.bias.data = layer.bias.data[perm]\n",
    "\n",
    "def adjust_input_weights(layer, perm):\n",
    "    \"\"\"\n",
    "    Adjusts the input wei\n",
    "    ghts of a layer according to the permutation of the previous layer.\n",
    "    Args:\n",
    "        layer: The layer to adjust.\n",
    "        perm: The permutation array of the previous layer.\n",
    "    \"\"\"\n",
    "    layer.weight.data = layer.weight.data[:, perm]\n",
    "    \n",
    "def generate_permutation_matrix(hidden_dim):\n",
    "    \"\"\"Generates a random permutation matrix.\"\"\"\n",
    "    perm = np.random.permutation(hidden_dim)\n",
    "    return torch.tensor(perm, dtype=torch.long)\n",
    "\n",
    "def compute_similarity_matrix(weights_a, weights_b):\n",
    "    \"\"\"\n",
    "    Computes the similarity matrix for two layers' weights.\n",
    "    \"\"\"\n",
    "    weights_a = weights_a.view(weights_a.size(0), -1)\n",
    "    weights_b = weights_b.view(weights_b.size(0), -1)\n",
    "    return torch.matmul(weights_a, weights_b.T)\n",
    "\n",
    "def get_permuted_weights(weights, perm):\n",
    "    \"\"\"\n",
    "    Permutes the rows of weights based on the given permutation.\n",
    "    \"\"\"\n",
    "    return weights[perm, :]\n",
    "\n",
    "\n",
    "def weight_matching(rng, model_a, model_b, max_iter=100, init_perm=None):\n",
    "    \"\"\"\n",
    "    Optimizes permutations to match Model B to Model A.\n",
    "    \"\"\"\n",
    "    layers = ['fc1', 'fc2', 'fc3']\n",
    "    perm_sizes = {layer: getattr(model_a, layer).weight.size(0) for layer in layers[:-1]}\n",
    "    perm = {layer: np.arange(size) for layer, size in perm_sizes.items()} if init_perm is None else init_perm\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        progress = False\n",
    "        for layer in layers[:-1]:  # Exclude the output layer (fc3)\n",
    "            n = perm_sizes[layer]\n",
    "            similarity_matrix = compute_similarity_matrix(\n",
    "                getattr(model_a, layer).weight.data,\n",
    "                get_permuted_weights(getattr(model_b, layer).weight.data, perm[layer])\n",
    "            )\n",
    "            row_ind, col_ind = linear_sum_assignment(similarity_matrix.numpy(), maximize=True)\n",
    "\n",
    "            old_score = np.sum(similarity_matrix.numpy()[np.arange(n), perm[layer]])\n",
    "            new_score = np.sum(similarity_matrix.numpy()[np.arange(n), col_ind])\n",
    "\n",
    "            if new_score > old_score:\n",
    "                perm[layer] = col_ind\n",
    "                progress = True\n",
    "\n",
    "        if not progress:\n",
    "            break\n",
    "\n",
    "    return perm, new_score\n",
    "\n",
    "def rebase_model_b_to_a(rng, model_a, model_b, max_iter=100):\n",
    "    \"\"\"\n",
    "    Rebases Model B to match Model A using weight matching.\n",
    "    \"\"\"\n",
    "    # Generate initial permutations\n",
    "    init_perm = {layer: generate_permutation_matrix(getattr(model_a, layer).weight.size(0)) for layer in ['fc1', 'fc2']}\n",
    "    \n",
    "    # Perform weight matching\n",
    "    permutations, score = weight_matching(rng, model_a, model_b, max_iter=max_iter, init_perm=init_perm)\n",
    "    \n",
    "    # Apply the permutations to Model B\n",
    "    model_b = permute_model(model_b, [permutations['fc1'], permutations['fc2']])\n",
    "    \n",
    "    return model_b, permutations, score\n",
    "\n",
    "def load_model_weights(model, weight_path):\n",
    "    # Load weights and biases\n",
    "    weights, biases = torch.load(weight_path)\n",
    "    model.fc1.weight.data = weights[0]\n",
    "    model.fc2.weight.data = weights[1]\n",
    "    model.fc3.weight.data = weights[2]\n",
    "    model.fc1.bias.data = biases[0]\n",
    "    model.fc2.bias.data = biases[1]\n",
    "    model.fc3.bias.data = biases[2]\n",
    "    return model\n",
    "\n",
    "def reconstruct_model(model, final_permutations):\n",
    "    \"\"\"\n",
    "    Reconstruct model_b by applying the final permutations to its layers.\n",
    "    Args:\n",
    "        model_b (MLP): The model to be reconstructed.\n",
    "        final_permutations (dict): Dictionary containing layer-wise permutations.\n",
    "    Returns:\n",
    "        MLP: The reconstructed model.\n",
    "    \"\"\"\n",
    "    # Apply permutations to fc1 layer\n",
    "    apply_permutation(model.fc1, final_permutations[1]['fc1'])\n",
    "    adjust_input_weights(model.fc2, final_permutations[1]['fc1'])\n",
    "    \n",
    "    # Apply permutations to fc2 layer\n",
    "    apply_permutation(model.fc2, final_permutations[1]['fc2'])\n",
    "    adjust_input_weights(model.fc3, final_permutations[1]['fc2'])\n",
    "    \n",
    "    # Return the reconstructed model\n",
    "    return model\n",
    "\n",
    "def extract_weights_and_biases(model):\n",
    "    \"\"\"Flatten the weights and biases of each layer in the model into a single vector.\"\"\"\n",
    "    all_weights_biases = []\n",
    "    \n",
    "    # Flatten weights and biases for each layer\n",
    "    for layer_name in ['fc1', 'fc2', 'fc3']:\n",
    "        weights = getattr(model, layer_name).weight.data.numpy().flatten()  # Flatten the weights\n",
    "        biases = getattr(model, layer_name).bias.data.numpy().flatten()    # Flatten the biases\n",
    "        all_weights_biases.extend(weights)\n",
    "        all_weights_biases.extend(biases)\n",
    "    \n",
    "    return np.array(all_weights_biases)\n",
    "\n",
    "def get_permuted_models_data(ref_point=0, N = 10, path = f\"models/reduced_mlp_weights_{0}.pt\"):\n",
    "    ref_model = MLP()\n",
    "    ref_model_path = path #f\"models/reduced_mlp_weights_{ref_point}.pt\"\n",
    "#     ref_model_path =   f\"models/dropout_mlp_weights_{ref_point}.pt\"\n",
    "\n",
    "    ref_model = load_model_weights(ref_model, ref_model_path)\n",
    "    \n",
    "    org_models=[]\n",
    "    permuted_models = []\n",
    "    full_times = []\n",
    "    rebasin_times = []\n",
    "    scores = []\n",
    "    rng = np.random.default_rng(42)\n",
    "\n",
    "    for i in range(0,N):\n",
    "        if i == ref_point:\n",
    "            continue\n",
    "        all_start = time.time() # start timing\n",
    "        model_path = f\"models/reduced_mlp_weights_{i}.pt\"\n",
    "#         model_path = f\"models/dropout_mlp_weights_{i}.pt\"\n",
    "        \n",
    "        model = MLP()\n",
    "        model = load_model_weights(model, model_path)\n",
    "        org_models.append(model)\n",
    "        loaded_model = time.time() # end timing for loading the model from .pth file\n",
    "        \n",
    "        reconstructed_model, final_permutations, score = rebase_model_b_to_a(rng, ref_model, model, max_iter=100)\n",
    "        scores.append(score)\n",
    "        permuted_models.append(reconstructed_model)\n",
    "        all_end = time.time() # end timing for the entire loop\n",
    "        \n",
    "        full_times.append(all_end - all_start)\n",
    "        rebasin_times.append(all_end - loaded_model)\n",
    "        \n",
    "#         print(f\"Org model accuracy:{test_mlp(model, test_loader)} Reconstructed model accuracy:{test_mlp(reconstructed_model, test_loader)}\")\n",
    "    return org_models, permuted_models, scores, rebasin_times\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e9af90fe-26dd-41d7-bfee-e274d7e83df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "org_models, permuted_models, scores, rebasin_times = get_permuted_models_data(ref_point=0, N = 1200) # dropout = 180, norm = 780"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9417833-271a-4dc0-bbb4-87b36e663939",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLPGraphDatasetNeuronsFromList(torch.utils.data.Dataset):\n",
    "    def __init__(self, mlp_list):\n",
    "        \"\"\"\n",
    "        mlp_list: a list of MLP objects.\n",
    "        \"\"\"\n",
    "        self.models = mlp_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.models)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Get the MLP instance from the list.\n",
    "        mlp = self.models[idx]\n",
    "        # Extract weights and biases directly from the model's layers.\n",
    "        # We assume the model has attributes fc1, fc2, fc3.\n",
    "        weights = [mlp.fc1.weight, mlp.fc2.weight, mlp.fc3.weight]\n",
    "        biases = [mlp.fc1.bias, mlp.fc2.bias, mlp.fc3.bias]\n",
    "\n",
    "        # --- Build Node Features ---\n",
    "        # Input layer: create nodes based on the input dimension of fc1.\n",
    "        input_dim = weights[0].shape[1]\n",
    "        input_feats = torch.zeros(input_dim, 1)\n",
    "        # For subsequent layers, use the bias of each layer as the node feature.\n",
    "        node_features = [input_feats]\n",
    "        for b in biases:\n",
    "            node_feats = b.view(-1, 1)\n",
    "            node_features.append(node_feats)\n",
    "        # Concatenate features from all layers; total nodes = input_dim + sum(layer output sizes)\n",
    "        x = torch.cat(node_features, dim=0)\n",
    "\n",
    "        # --- Build Edges and Edge Attributes ---\n",
    "        edge_index_list = []\n",
    "        edge_attr_list = []\n",
    "        offset = 0  # starting index for current layer's nodes\n",
    "        # Iterate over each weight matrix corresponding to a layer.\n",
    "        for w in weights:\n",
    "            in_dim = w.shape[1]    # number of nodes in source layer\n",
    "            out_dim = w.shape[0]   # number of nodes in destination layer\n",
    "            src_offset = offset\n",
    "            dst_offset = offset + in_dim\n",
    "            for i_out in range(out_dim):\n",
    "                for j_in in range(in_dim):\n",
    "                    src = src_offset + j_in\n",
    "                    dst = dst_offset + i_out\n",
    "                    edge_index_list.append([src, dst])\n",
    "                    edge_attr_list.append([w[i_out, j_in].item()])\n",
    "            offset += in_dim  # move the offset for the next layer\n",
    "\n",
    "        # Convert lists to torch tensors.\n",
    "        edge_index = torch.tensor(edge_index_list, dtype=torch.long).t().contiguous()\n",
    "        edge_attr = torch.tensor(edge_attr_list, dtype=torch.float)\n",
    "\n",
    "        return Data(x=x, edge_index=edge_index, edge_attr=edge_attr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a1d0f37-1964-4338-8a81-f4140ba81555",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = MLPGraphDatasetNeuronsFromList(permuted_models)\n",
    "loader = DataLoader(dataset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf0868c-5858-4d8c-b3e6-f114af52b21b",
   "metadata": {},
   "source": [
    "# Build Denoising Graph Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fbba105c-3d3d-47e6-b50b-3926475290d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import NNConv, GraphNorm\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 2) Encoder: edge‚Äêconditioned graph conv with residuals & normalization\n",
    "# -----------------------------------------------------------------------------\n",
    "class EdgeConditionedEncoder(nn.Module):\n",
    "    def __init__(self, in_ch, hidden_ch, latent_dim):\n",
    "        super().__init__()\n",
    "        # MLP to produce per-edge weight kernels\n",
    "        self.edge_mlp1 = nn.Sequential(\n",
    "            nn.Linear(1, in_ch * hidden_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(in_ch * hidden_ch, in_ch * hidden_ch)\n",
    "        )\n",
    "        self.conv1 = NNConv(in_ch, hidden_ch, self.edge_mlp1, aggr='mean')\n",
    "        self.norm1 = GraphNorm(hidden_ch)\n",
    "\n",
    "        self.edge_mlp2 = nn.Sequential(\n",
    "            nn.Linear(1, hidden_ch * hidden_ch),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_ch * hidden_ch, hidden_ch * hidden_ch)\n",
    "        )\n",
    "        self.conv2 = NNConv(hidden_ch, hidden_ch, self.edge_mlp2, aggr='mean')\n",
    "        self.norm2 = GraphNorm(hidden_ch)\n",
    "\n",
    "        # final mapping to latent space\n",
    "        self.lin = nn.Linear(hidden_ch, latent_dim)\n",
    "\n",
    "    def forward(self, x, edge_index, edge_weight):\n",
    "        ew = edge_weight.view(-1,1)  # [E,1]\n",
    "        h0 = x\n",
    "        h  = F.relu(self.norm1(self.conv1(x, edge_index, ew)))\n",
    "        h  = h + h0                        # residual\n",
    "        h1 = h\n",
    "        h  = F.relu(self.norm2(self.conv2(h, edge_index, ew)))\n",
    "        h  = h + h1                        # residual\n",
    "        z  = self.lin(h)                   # [N, latent_dim]\n",
    "        return z\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 3) Joint Decoder: reconstruct both edge weights & node features\n",
    "# -----------------------------------------------------------------------------\n",
    "class JointDecoder(nn.Module):\n",
    "    def __init__(self, latent_dim, hidden_dim=64):\n",
    "        super().__init__()\n",
    "        # project node embeddings\n",
    "        self.node_proj   = nn.Linear(latent_dim, hidden_dim)\n",
    "        # project raw edge weights\n",
    "        self.edge_proj   = nn.Linear(1, hidden_dim)\n",
    "        # MLP heads\n",
    "        self.edge_h1     = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.edge_out    = nn.Linear(hidden_dim, 1)\n",
    "        self.node_h1     = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.node_out    = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, z, edge_index, edge_weight):\n",
    "        # z: [N, latent_dim]\n",
    "        # edge_index: [2, E], edge_weight: [E,1] or [E]\n",
    "        if edge_weight.dim() == 1:\n",
    "            ew = edge_weight.unsqueeze(1)\n",
    "        else:\n",
    "            ew = edge_weight  # [E,1]\n",
    "\n",
    "        # project node embeddings\n",
    "        h_n = F.relu(self.node_proj(z))           # [N, H]\n",
    "\n",
    "        # build edge-specific features\n",
    "        src, dst = edge_index\n",
    "        h_e = h_n[src] + h_n[dst]                  # [E, H]\n",
    "        h_ew = F.relu(self.edge_proj(ew))          # [E, H]\n",
    "        h_comb = F.relu(h_e + h_ew)                # [E, H]\n",
    "\n",
    "        # edge reconstruction\n",
    "        he = F.relu(self.edge_h1(h_comb))\n",
    "        edge_pred = self.edge_out(he).squeeze()    # [E]\n",
    "\n",
    "        # node reconstruction\n",
    "        hn = F.relu(self.node_h1(h_n))\n",
    "        node_pred = self.node_out(hn).squeeze()    # [N]\n",
    "\n",
    "        return edge_pred, node_pred\n",
    "\n",
    "# -----------------------------------------------------------------------------\n",
    "# 4) Graph Autoencoder wrapper\n",
    "# -----------------------------------------------------------------------------\n",
    "class GraphAutoEncoder(nn.Module):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "\n",
    "    def forward(self, data):\n",
    "        z = self.encoder(data.x, data.edge_index, data.edge_attr.view(-1))\n",
    "        return z\n",
    "\n",
    "    def compute_loss(self, data):\n",
    "        z = self.encoder(data.x, data.edge_index, data.edge_attr.view(-1))\n",
    "        ep, npred = self.decoder(z, data.edge_index, data.edge_attr.view(-1))\n",
    "        loss_e = F.mse_loss(ep, data.edge_attr.view(-1))\n",
    "        loss_n = F.mse_loss(npred, data.x.view(-1))\n",
    "        return loss_e + loss_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4aa57a35-6842-4764-84ec-57b0f42ac4dc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 001, Recon Loss: 0.0185\n",
      "Epoch 002, Recon Loss: 0.0009\n",
      "Epoch 003, Recon Loss: 0.0002\n",
      "Epoch 004, Recon Loss: 0.0001\n",
      "Epoch 005, Recon Loss: 0.0000\n",
      "Epoch 006, Recon Loss: 0.0000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-beaab67eff59>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mtotal_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    524\u001b[0m             )\n\u001b[0;32m--> 525\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    526\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    527\u001b[0m         )\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    265\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    268\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    742\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    743\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 744\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    745\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    746\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Assume you have a Python list of MLPs called `mlp_list`\n",
    "# dataset = MLPGraphDatasetNeuronsFromList(mlp_list)\n",
    "# loader  = DataLoader(dataset, batch_size=8, shuffle=True)\n",
    "\n",
    "\n",
    "encoder = EdgeConditionedEncoder(in_ch=1,   hidden_ch=16, latent_dim=128)\n",
    "decoder = JointDecoder(latent_dim=128,        hidden_dim=256)\n",
    "gae     = GraphAutoEncoder(encoder, decoder)\n",
    "\n",
    "optimizer = torch.optim.Adam(gae.parameters(), lr=5e-4)\n",
    "\n",
    "# training loop\n",
    "for epoch in range(1, 25):\n",
    "    gae.train()\n",
    "    total_loss = 0\n",
    "    for data in loader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = gae.compute_loss(data)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item()\n",
    "    print(f\"Epoch {epoch:03d}, Recon Loss: {total_loss/len(loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d4dca275-eaeb-4a64-9796-51f66f7f3418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Denoising GAE has 234818 parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    \"\"\"\n",
    "    Function: Count the learnable params in a portion of the model\n",
    "    Args: model segment (ie, encoder, decoder, entire model)\n",
    "    Returns: the number of learnable params in that model/segment\n",
    "    \"\"\"\n",
    "    total_params = sum(p.numel() for p in model.parameters())\n",
    "    return total_params\n",
    "\n",
    "print(f\"Denoising GAE has {count_parameters(gae)} parameters\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc72d26-87aa-403b-b645-85a2a3ffd010",
   "metadata": {},
   "source": [
    "# Examine performance: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd3d7b4d-e343-4894-9d84-d615ede8968b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "def vgae_to_mlp(generated_data):\n",
    "    \"\"\"\n",
    "    generated_data: a Data object that has the reconstructed node features (x)\n",
    "    and edge attributes (edge_attr).  \n",
    "    The original graph was built as:\n",
    "      - First 196 nodes: input layer,\n",
    "      - Next 32 nodes: fc1 neurons,\n",
    "      - Next 32 nodes: fc2 neurons,\n",
    "      - Next 10 nodes: fc3 neurons.\n",
    "    Edge ordering is:\n",
    "      - fc1: edges from input (196 nodes) to fc1 (32 nodes) in a nested loop:\n",
    "             for i in range(32): for j in range(196)\n",
    "      - fc2: edges from fc1 (32 nodes) to fc2 (32 nodes)\n",
    "      - fc3: edges from fc2 (32 nodes) to fc3 (10 nodes)\n",
    "    This function instantiates a new MLP and sets its weights and biases from the generated outputs.\n",
    "    \"\"\"\n",
    "    x_rec = generated_data.x.squeeze()  # shape: (196+32+32+10,)\n",
    "    edge_attr_rec = generated_data.edge_attr  # shape: (32*196 + 32*32 + 10*32,)\n",
    "\n",
    "    # Extract biases.\n",
    "    fc1_bias = x_rec[196:196+32]\n",
    "    fc2_bias = x_rec[196+32:196+32+32]\n",
    "    fc3_bias = x_rec[196+32+32:196+32+32+10]\n",
    "\n",
    "    # Extract edge weights.\n",
    "    # For fc1: first 32*196 values.\n",
    "    fc1_weight = edge_attr_rec[:32*196].view(32, 196)\n",
    "    # For fc2: next 32*32 values.\n",
    "    start_fc2 = 32*196\n",
    "    fc2_weight = edge_attr_rec[start_fc2:start_fc2+32*32].view(32, 32)\n",
    "    # For fc3: remaining 10*32 values.\n",
    "    start_fc3 = start_fc2 + 32*32\n",
    "    fc3_weight = edge_attr_rec[start_fc3:start_fc3+10*32].view(10, 32)\n",
    "\n",
    "    # Create a new instance of the MLP.\n",
    "    new_mlp = MLP()\n",
    "    # Assign weights and biases.\n",
    "    with torch.no_grad():\n",
    "        new_mlp.fc1.weight.copy_(fc1_weight)\n",
    "        new_mlp.fc1.bias.copy_(fc1_bias)\n",
    "        new_mlp.fc2.weight.copy_(fc2_weight)\n",
    "        new_mlp.fc2.bias.copy_(fc2_bias)\n",
    "        new_mlp.fc3.weight.copy_(fc3_weight)\n",
    "        new_mlp.fc3.bias.copy_(fc3_bias)\n",
    "    return new_mlp\n",
    "\n",
    "\n",
    "def reconstruct_nth_mlp(gae, dataset, n = 0, device = device):\n",
    "    \"\"\"\n",
    "    Reconstructs the first MLP in `dataset` via your deterministic GAE.\n",
    "    \n",
    "    Args:\n",
    "        gae      : the trained GraphAutoEncoder (with .encoder and .decoder).\n",
    "        dataset  : your MLPGraphDatasetNeuronsFromList (or equivalent).\n",
    "        device   : torch.device ('cpu' or 'cuda').\n",
    "    \n",
    "    Returns:\n",
    "        new_mlp  : an MLP instance whose weights & biases were produced\n",
    "                   by the GAE reconstructions.\n",
    "    \"\"\"\n",
    "    # 1) Grab the first graph\n",
    "    data = dataset[n]\n",
    "    data = data.to(device)\n",
    "    \n",
    "    # 2) Run through encoder + decoder\n",
    "    gae.eval()\n",
    "    with torch.no_grad():\n",
    "        # encode\n",
    "        z = gae.encoder(data.x, data.edge_index, data.edge_attr.view(-1))\n",
    "        # decode edges & nodes\n",
    "        if hasattr(gae.decoder, 'forward'):\n",
    "            # JointDecoder interface: returns (edge_pred, node_pred)\n",
    "            edge_pred, node_pred = gae.decoder(z, data.edge_index, data.edge_attr.view(-1))\n",
    "        else:\n",
    "            # If you have separate decoders:\n",
    "            edge_pred = gae.edge_decoder(z, data.edge_index, data.edge_attr.view(-1))\n",
    "            node_pred = gae.node_decoder(z, data.edge_index, data.edge_attr.view(-1))\n",
    "    \n",
    "    # 3) Build a new Data object with the reconstructions\n",
    "    rec_data = Data(\n",
    "        x         = node_pred.unsqueeze(1),      # [N,1]\n",
    "        edge_index= data.edge_index,             # same topology\n",
    "        edge_attr = edge_pred.unsqueeze(1)       # [E,1]\n",
    "    )\n",
    "    \n",
    "    # 4) Convert graph back to an MLP\n",
    "    # This is the same vgae_to_mlp function from before:\n",
    "    new_mlp = vgae_to_mlp(rec_data)\n",
    "    return new_mlp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c53a3ebc-61aa-4025-bc9c-61633fa4488f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed MLP test accuracy: 92.78%\n"
     ]
    }
   ],
   "source": [
    "# assuming you have:\n",
    "#   gae         : your trained GraphAutoEncoder\n",
    "#   dataset     : your MLPGraphDatasetNeuronsFromList instance\n",
    "#   device      : torch.device('cuda' or 'cpu')\n",
    "#   test_loader : your MNIST DataLoader\n",
    "#   test_mlp    : function(mlp, device, test_loader) -> accuracy/loss\n",
    "\n",
    "# reconstruct one MLP and immediately test it\n",
    "generated_mlp = reconstruct_nth_mlp(gae, dataset)\n",
    "accuracy = test_mlp(generated_mlp, test_loader)\n",
    "print(f\"Reconstructed MLP test accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e6613d5d-bb97-44f1-8dff-31b61e449834",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed MLP test accuracy: 92.78%\n",
      "Reconstructed MLP test accuracy: 91.73%\n",
      "Reconstructed MLP test accuracy: 92.66%\n",
      "Reconstructed MLP test accuracy: 93.72%\n",
      "Reconstructed MLP test accuracy: 91.67%\n",
      "Reconstructed MLP test accuracy: 90.42%\n",
      "Reconstructed MLP test accuracy: 92.51%\n",
      "Reconstructed MLP test accuracy: 93.69%\n",
      "Reconstructed MLP test accuracy: 85.78%\n",
      "Reconstructed MLP test accuracy: 93.5%\n",
      "Reconstructed MLP test accuracy: 93.32%\n",
      "Reconstructed MLP test accuracy: 93.92%\n",
      "Reconstructed MLP test accuracy: 93.31%\n",
      "Reconstructed MLP test accuracy: 93.48%\n",
      "Reconstructed MLP test accuracy: 92.94%\n",
      "Reconstructed MLP test accuracy: 92.49%\n",
      "Reconstructed MLP test accuracy: 92.13%\n",
      "Reconstructed MLP test accuracy: 93.22%\n",
      "Reconstructed MLP test accuracy: 93.26%\n",
      "Reconstructed MLP test accuracy: 93.17%\n",
      "Reconstructed MLP test accuracy: 89.92%\n",
      "Reconstructed MLP test accuracy: 90.93%\n",
      "Reconstructed MLP test accuracy: 93.93%\n",
      "Reconstructed MLP test accuracy: 91.42%\n",
      "Reconstructed MLP test accuracy: 91.79%\n",
      "Reconstructed MLP test accuracy: 92.52%\n",
      "Reconstructed MLP test accuracy: 93.15%\n",
      "Reconstructed MLP test accuracy: 93.54%\n",
      "Reconstructed MLP test accuracy: 92.99%\n",
      "Reconstructed MLP test accuracy: 92.45%\n",
      "Reconstructed MLP test accuracy: 93.42%\n",
      "Reconstructed MLP test accuracy: 92.9%\n",
      "Reconstructed MLP test accuracy: 92.83%\n",
      "Reconstructed MLP test accuracy: 93.29%\n",
      "Reconstructed MLP test accuracy: 91.7%\n",
      "Reconstructed MLP test accuracy: 93.5%\n",
      "Reconstructed MLP test accuracy: 92.37%\n",
      "Reconstructed MLP test accuracy: 93.07%\n",
      "Reconstructed MLP test accuracy: 93.41%\n",
      "Reconstructed MLP test accuracy: 92.93%\n",
      "Reconstructed MLP test accuracy: 92.84%\n",
      "Reconstructed MLP test accuracy: 93.26%\n",
      "Reconstructed MLP test accuracy: 91.61%\n",
      "Reconstructed MLP test accuracy: 93.64%\n",
      "Reconstructed MLP test accuracy: 93.07%\n",
      "Reconstructed MLP test accuracy: 92.11%\n",
      "Reconstructed MLP test accuracy: 86.77%\n",
      "Reconstructed MLP test accuracy: 93.5%\n",
      "Reconstructed MLP test accuracy: 92.07%\n",
      "Reconstructed MLP test accuracy: 92.17%\n",
      "Reconstructed MLP test accuracy: 93.05%\n",
      "Reconstructed MLP test accuracy: 93.07%\n",
      "Reconstructed MLP test accuracy: 91.04%\n",
      "Reconstructed MLP test accuracy: 92.71%\n",
      "Reconstructed MLP test accuracy: 90.73%\n",
      "Reconstructed MLP test accuracy: 92.95%\n",
      "Reconstructed MLP test accuracy: 93.38%\n",
      "Reconstructed MLP test accuracy: 93.13%\n",
      "Reconstructed MLP test accuracy: 91.6%\n",
      "Reconstructed MLP test accuracy: 94.12%\n",
      "Reconstructed MLP test accuracy: 92.93%\n",
      "Reconstructed MLP test accuracy: 93.61%\n",
      "Reconstructed MLP test accuracy: 92.88%\n",
      "Reconstructed MLP test accuracy: 92.08%\n",
      "Reconstructed MLP test accuracy: 92.04%\n",
      "Reconstructed MLP test accuracy: 93.88%\n",
      "Reconstructed MLP test accuracy: 93.78%\n",
      "Reconstructed MLP test accuracy: 93.33%\n",
      "Reconstructed MLP test accuracy: 87.06%\n",
      "Reconstructed MLP test accuracy: 94.1%\n",
      "Reconstructed MLP test accuracy: 93.65%\n",
      "Reconstructed MLP test accuracy: 89.32%\n",
      "Reconstructed MLP test accuracy: 91.2%\n",
      "Reconstructed MLP test accuracy: 93.33%\n",
      "Reconstructed MLP test accuracy: 93.41%\n",
      "Reconstructed MLP test accuracy: 93.11%\n",
      "Reconstructed MLP test accuracy: 93.09%\n",
      "Reconstructed MLP test accuracy: 93.65%\n",
      "Reconstructed MLP test accuracy: 91.67%\n",
      "Reconstructed MLP test accuracy: 93.33%\n",
      "Reconstructed MLP test accuracy: 94.02%\n",
      "Reconstructed MLP test accuracy: 93.6%\n",
      "Reconstructed MLP test accuracy: 93.04%\n",
      "Reconstructed MLP test accuracy: 92.31%\n",
      "Reconstructed MLP test accuracy: 93.3%\n",
      "Reconstructed MLP test accuracy: 93.44%\n",
      "Reconstructed MLP test accuracy: 93.32%\n",
      "Reconstructed MLP test accuracy: 93.01%\n",
      "Reconstructed MLP test accuracy: 91.75%\n",
      "Reconstructed MLP test accuracy: 90.84%\n",
      "Reconstructed MLP test accuracy: 93.17%\n",
      "Reconstructed MLP test accuracy: 93.29%\n",
      "Reconstructed MLP test accuracy: 94.13%\n",
      "Reconstructed MLP test accuracy: 92.23%\n",
      "Reconstructed MLP test accuracy: 93.04%\n",
      "Reconstructed MLP test accuracy: 92.54%\n",
      "Reconstructed MLP test accuracy: 92.69%\n",
      "Reconstructed MLP test accuracy: 91.91%\n",
      "Reconstructed MLP test accuracy: 93.13%\n",
      "Reconstructed MLP test accuracy: 91.5%\n"
     ]
    }
   ],
   "source": [
    "n = 100\n",
    "accuracies = []\n",
    "for i in range(n): \n",
    "    generated_mlp = reconstruct_nth_mlp(gae, dataset, i)\n",
    "    accuracy = test_mlp(generated_mlp, test_loader)\n",
    "    accuracies.append(accuracy)\n",
    "    print(f\"Reconstructed MLP test accuracy: {accuracy}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5b545e2b-b087-432e-9706-1d890853e641",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Histogram of 100 first MLP reconstructions' performances on MNIST test data\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(accuracies)\n",
    "print(f\"Histogram of 100 first MLP reconstructions' performances on MNIST test data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d415003a-1799-4008-bd63-b4bc8759f2c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
