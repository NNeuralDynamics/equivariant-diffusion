{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e00fe6c8-6444-4a77-ada2-472cd056562a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "\n",
    "from experiments.data import INRDataset\n",
    "from experiments.utils import (\n",
    "    common_parser,\n",
    "    count_parameters,\n",
    "    get_device,\n",
    "    set_logger,\n",
    "    set_seed,\n",
    "    str2bool,\n",
    ")\n",
    "from nn.models import DWSModelForClassification, MLPModelForClassification , DWSModel\n",
    "\n",
    "from experiments.mnist.generate_data_splits import generate_splits\n",
    "from experiments.mnist.compute_statistics import compute_stats\n",
    "\n",
    "set_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4acf94d0-9e9d-4cd9-9c5d-4a558590a72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77cfddde-c01f-40f6-8ac4-27a7abee2159",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "torch.backends.cudnn.enabled = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d82391f-f77d-4cae-addc-a12ab52ff932",
   "metadata": {},
   "outputs": [],
   "source": [
    "# generate_splits(data_path=\"notebooks/dataset/mnist-inrs\", save_path=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e8f6846-9026-48f1-9ec0-7a45f5fd201b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute_stats(data_path=\"notebooks/dataset/mnist_splits.json\", save_path=\"dataset\", batch_size=1024)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feea4da9-7279-4d80-be09-6b73ec3334e2",
   "metadata": {
    "id": "cb3a1c45",
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## INR Dataset\n",
    "\n",
    "We create INR Datasets and Dataloaders, and visualize some INRs (by reconstruction the images).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cbcf4cd-b6f2-48ff-a234-a2369ed9c41f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/talisman/sgupta/DWSNets/equivariant-diffusion\n"
     ]
    }
   ],
   "source": [
    "#Loading inr data we created while mnist training\n",
    "import os\n",
    "current_working_directory = os.getcwd()\n",
    "print(current_working_directory)\n",
    "path = current_working_directory + \"/notebooks/dataset/mnist_splits.json\"\n",
    "statistics_path = current_working_directory + \"/notebooks/dataset/statistics.pth\"\n",
    "normalize = True\n",
    "augmentation = True\n",
    "\n",
    "batch_size = 64\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd40c5f4-1892-4c10-8ca1-a70f9ddb8f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.utils import save_image, make_grid\n",
    "# import torch\n",
    "\n",
    "# from experiments.data import INRImageDataset\n",
    "# from experiments.utils import set_seed\n",
    "# import matplotlib.pyplot as plt\n",
    "# dataset = INRImageDataset(\n",
    "#     path=path,  # path to splits json file\n",
    "#     augmentation=False,\n",
    "#     split=\"train\",\n",
    "# )\n",
    "\n",
    "# loader = torch.utils.data.DataLoader(dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# dataset_aug = INRImageDataset(\n",
    "#     path=path,  # path to splits json file\n",
    "#     augmentation=True,\n",
    "#     split=\"train\",\n",
    "# )\n",
    "# loader_aug = torch.utils.data.DataLoader(dataset_aug, batch_size=64, shuffle=False)\n",
    "\n",
    "# batch = next(iter(loader))\n",
    "# batch_aug = next(iter(loader_aug))\n",
    "\n",
    "# fig, axs = plt.subplots(1, 2, figsize=(10,20)) \n",
    "\n",
    "# axs[0].imshow(make_grid(batch.image.squeeze(-1)).permute(1, 2, 0).clip(0, 1))\n",
    "# axs[0].set_title('Recunstracted Images from INRs')\n",
    "\n",
    "# axs[1].imshow(make_grid(batch_aug.image.squeeze(-1)).permute(1, 2, 0).clip(0, 1))\n",
    "# axs[1].set_title('Recunstracted Images from Augmented INRs')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "22e4161e-7af3-4641-bae2-5491126553a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.stats = torch.load(statistics_path, map_location=\"cpu\")\n",
      "2024-10-15 09:42:26,841 - root - INFO - train size 55000, val size 5000, test size 10000\n"
     ]
    }
   ],
   "source": [
    "train_set = INRDataset(\n",
    "        path=path,\n",
    "        split=\"train\",\n",
    "        normalize=normalize,\n",
    "        augmentation=augmentation,\n",
    "        statistics_path=statistics_path,\n",
    "    )\n",
    "\n",
    "val_set = INRDataset(\n",
    "    path=path,\n",
    "    split=\"val\",\n",
    "    normalize=normalize,\n",
    "    statistics_path=statistics_path,\n",
    ")\n",
    "\n",
    "test_set = INRDataset(\n",
    "    path=path,\n",
    "    split=\"test\",\n",
    "    normalize=normalize,\n",
    "    statistics_path=statistics_path,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "logging.info(\n",
    "    f\"train size {len(train_set)}, \"\n",
    "    f\"val size {len(val_set)}, \"\n",
    "    f\"test size {len(test_set)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b7f09531-4f84-437d-9915-495c4163546d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(torch.Size([2, 32]), torch.Size([32, 32]), torch.Size([32, 1])) (torch.Size([32]), torch.Size([32]), torch.Size([1]))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n"
     ]
    }
   ],
   "source": [
    "point = train_set.__getitem__(4)\n",
    "weight_shapes = tuple(w.shape[:2] for w in point.weights)\n",
    "bias_shapes = tuple(b.shape[:1] for b in point.biases)\n",
    "print(weight_shapes,bias_shapes)\n",
    "# print(point.weights,point.biases,point.label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "92ee3a35-8300-429c-bc2b-2da82aa6d514",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_weight_shapes = (torch.Size([2, 8]), torch.Size([8, 8]), torch.Size([8, 1]))\n",
    "new_bias_shapes = (torch.Size([8]), torch.Size([8]), torch.Size([1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea273fcd-5612-4b2c-8917-f139580fbb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from nn.layers import BN, DWSLayer,InvariantLayer, Dropout, ReLU\n",
    "from nn.layers.base import BaseLayer,GeneralSetLayer\n",
    "\n",
    "class DWSEncoder(BaseLayer):\n",
    "    def __init__(\n",
    "       self,\n",
    "        weight_shapes,\n",
    "        bias_shapes,\n",
    "        input_features,\n",
    "        hidden_dims,\n",
    "        downsample_dim,\n",
    "        n_hidden=2,\n",
    "        reduction=\"max\",\n",
    "        bias=True,\n",
    "        n_fc_layers=1,\n",
    "        num_heads=4,\n",
    "        set_layer=\"sab\",\n",
    "        add_layer_skip=False,\n",
    "        input_dim_downsample=None,\n",
    "        init_scale=1.,\n",
    "        init_off_diag_scale_penalty=1.,\n",
    "        bn=False,\n",
    "        dropout_rate = 0.001,\n",
    "        diagonal=False,\n",
    "    ):\n",
    "        super().__init__(\n",
    "            in_features=input_features,\n",
    "            out_features=hidden_dims,\n",
    "            bias=bias,\n",
    "            reduction=reduction,\n",
    "            n_fc_layers=n_fc_layers,\n",
    "            num_heads=num_heads,\n",
    "            set_layer=set_layer,\n",
    "        )\n",
    "\n",
    "        assert len(weight_shapes) > 2, \"The implementation only supports networks with more than 2 layers.\"\n",
    "\n",
    "        self.downsample_dim = downsample_dim\n",
    "        self.bias = bias\n",
    "        self.n_fc_layers = n_fc_layers\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.skip = self._get_mlp(\n",
    "            in_features=input_features,\n",
    "            out_features=input_features,\n",
    "            bias=bias,\n",
    "        )\n",
    "        \n",
    "        self.InitialLayer = DWSModel(\n",
    "            weight_shapes= weight_shapes,\n",
    "            bias_shapes= bias_shapes,\n",
    "            input_features=input_features,\n",
    "            hidden_dim=hidden_dims,\n",
    "            n_hidden=n_hidden,\n",
    "            reduction=reduction,\n",
    "            bias=bias,\n",
    "            output_features=input_features,\n",
    "            n_fc_layers=n_fc_layers,\n",
    "            num_heads=num_heads,\n",
    "            set_layer=set_layer,\n",
    "            dropout_rate=dropout_rate,\n",
    "            input_dim_downsample=input_dim_downsample,\n",
    "            init_scale=init_scale,\n",
    "            init_off_diag_scale_penalty=init_off_diag_scale_penalty,\n",
    "            bn=bn,\n",
    "            add_skip=False,\n",
    "            add_layer_skip=add_layer_skip,\n",
    "            diagonal=diagonal,\n",
    "        )   \n",
    "\n",
    "    def downsample_input_weights(self, inputs, downsample_dim):\n",
    "        \"\"\"Downsample the input weights to the specified dimensions.\"\"\"\n",
    "        inputs = list(inputs)\n",
    "\n",
    "        # Downsample first weight dimension [32,2,32,1] -> [32,2,8,1]\n",
    "        inputs[0] = self._downsample_weight(inputs[0], dim=2, downsample_dim = downsample_dim)\n",
    "        # Downsample second weight dimension [32,32,32,1] -> [32,8,8,1]\n",
    "        inputs[1] = self._downsample_weight(inputs[1], dim=1, downsample_dim = downsample_dim)\n",
    "        inputs[1] = self._downsample_weight(inputs[1], dim=2, downsample_dim = downsample_dim)\n",
    "\n",
    "        # Downsample third weight dimension [32,32,1,1] -> [32,8,1,1]\n",
    "        inputs[2] = self._downsample_weight(inputs[2], dim=1, downsample_dim = downsample_dim)\n",
    "\n",
    "        return tuple(inputs)\n",
    "\n",
    "    def downsample_input_biases(self, inputs, downsample_dim):\n",
    "        \"\"\"Downsample the input biases to the specified dimensions.\"\"\"\n",
    "        inputs = list(inputs)\n",
    "\n",
    "        # Downsample first bias dimension [32,32,1] -> [32,8,1]\n",
    "        inputs[0] = self._downsample_bias(inputs[0], downsample_dim= downsample_dim)\n",
    "\n",
    "        # Downsample second bias dimension [32,32,1] -> [32,8,1]\n",
    "        inputs[1] = self._downsample_bias(inputs[1], downsample_dim = downsample_dim)\n",
    "\n",
    "        return tuple(inputs)\n",
    "    \n",
    "    def batchNormLayer(self,weights, biases):\n",
    "        relu = nn.ReLU()\n",
    "        weights = tuple(relu(nn.BatchNorm2d(w.shape[1]).to(device)(w)) for w in weights)\n",
    "        biases = tuple(relu(nn.BatchNorm1d(b.shape[1]).to(device)(b.squeeze(-1)).unsqueeze(-1)) for b in biases)\n",
    "        return weights, biases\n",
    "\n",
    "    def forward(self, x: Tuple[Tuple[torch.tensor], Tuple[torch.tensor]]):\n",
    "        \"\"\"Forward pass through the encoder.\"\"\"\n",
    "        x = self.InitialLayer(x)\n",
    "        weights = self.downsample_input_weights(x[0], 24)\n",
    "        biases = self.downsample_input_biases(x[1], 24)\n",
    "        weights= (weights[0] + self.skip(weights[0]), weights[1] + self.skip(weights[1]) ,weights[2] + self.skip(weights[2]))\n",
    "        biases = (biases[0] + self.skip(biases[0]) , biases[1] + self.skip(biases[1]) ,biases[2] + self.skip(biases[2]))\n",
    "        weights, biases = self.batchNormLayer( weights, biases)\n",
    "        weights = self.downsample_input_weights(weights, 16)\n",
    "        biases = self.downsample_input_biases(biases, 16)\n",
    "        weights= (weights[0] + self.skip(weights[0]), weights[1] + self.skip(weights[1]) ,weights[2] + self.skip(weights[2]))\n",
    "        biases = (biases[0] + self.skip(biases[0]) , biases[1] + self.skip(biases[1]) ,biases[2] + self.skip(biases[2]))\n",
    "        weights, biases = self.batchNormLayer( weights, biases)\n",
    "        weights = self.downsample_input_weights(weights, self.downsample_dim)\n",
    "        biases = self.downsample_input_biases(biases, self.downsample_dim)\n",
    "        weights= (weights[0] + self.skip(weights[0]), weights[1] + self.skip(weights[1]) ,weights[2] + self.skip(weights[2]))\n",
    "        biases = (biases[0] + self.skip(biases[0]) , biases[1] + self.skip(biases[1]) ,biases[2] + self.skip(biases[2]))\n",
    "        out = (weights, biases)\n",
    "        return out\n",
    "\n",
    "    def _downsample_weight(self, weight, dim,downsample_dim):\n",
    "        d0 = weight.shape[dim]\n",
    "        down_sample = GeneralSetLayer(\n",
    "            in_features=d0,\n",
    "            out_features= downsample_dim,\n",
    "            reduction=\"attn\",\n",
    "            bias=self.bias,\n",
    "            n_fc_layers=self.n_fc_layers,\n",
    "            num_heads=self.num_heads,\n",
    "            set_layer=\"ds\",\n",
    "        ).to(device)\n",
    "        \n",
    "        wi = weight.permute(0, 3, 1, 2) if dim == 2 else weight.permute(0, 3, 2, 1)\n",
    "        wi = down_sample(wi)\n",
    "        return wi.permute(0, 2, 3, 1) if dim == 2 else wi.permute(0, 3, 2, 1)\n",
    "\n",
    "    def _downsample_bias(self, bias, downsample_dim):\n",
    "        d0 = bias.shape[1]\n",
    "        down_sample = GeneralSetLayer(\n",
    "            in_features=d0,\n",
    "            out_features=downsample_dim,\n",
    "            reduction=\"attn\",\n",
    "            bias=self.bias,\n",
    "            n_fc_layers=self.n_fc_layers,\n",
    "            num_heads=self.num_heads,\n",
    "            set_layer=\"ds\",\n",
    "        ).to(device)\n",
    "        \n",
    "        wi = bias.permute(0, 2, 1)\n",
    "        wi = down_sample(wi)\n",
    "        return wi.permute(0, 2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a6c6cf4-d6a1-4b48-a7aa-dd8a299bcfad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        if output_dim is None:\n",
    "            output_dim = input_dim \n",
    "\n",
    "        self.fc1 = nn.Linear(input_dim, output_dim)\n",
    "        self.fc2 = nn.Linear(output_dim, output_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.relu(self.fc1(x))  # First linear transformation + ReLU\n",
    "        x = self.fc2(x)  # Second linear transformation\n",
    "        return self.relu(x + residual)\n",
    "\n",
    "class BiasResidualBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(dim, dim)\n",
    "        self.fc2 = nn.Linear(dim, dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return self.relu(x + residual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "887d07a0-1f63-44ca-a13d-2ccdd6c82711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(Decoder, self).__init__()\n",
    "\n",
    "#         # For Weight Reconstruction\n",
    "#         self.fc_weight_1 = nn.Sequential(\n",
    "#             nn.Linear(8 * 2 * 1, 16 * 2 * 1),  # Assuming input size [batch, 8, 1, 1], adjust for your dimensions\n",
    "#             ResidualBlock(32),\n",
    "#             nn.Linear(16 * 2 * 1, 24 * 2 * 1),\n",
    "#             ResidualBlock(48),\n",
    "#             nn.Linear(24 * 2 * 1, 32 * 2 * 1),\n",
    "#         )\n",
    "#         self.fc_weight_21 = nn.Sequential(\n",
    "#             nn.Linear(8 * 8 * 1, 16 * 8 * 1),\n",
    "#             ResidualBlock(128),\n",
    "#             nn.Linear(16 * 8 * 1, 24 * 8 * 1),\n",
    "#             ResidualBlock(192),\n",
    "#             nn.Linear(24 * 8 * 1, 32 * 8 * 1),\n",
    "#         )\n",
    "#         self.fc_weight_22 = nn.Sequential(\n",
    "#             nn.Linear(8 * 32 * 1, 16 * 32 * 1),\n",
    "#             ResidualBlock(512),\n",
    "#             nn.Linear(16 * 32 * 1, 24 * 32 * 1),\n",
    "#             ResidualBlock(768),\n",
    "#             nn.Linear(24 * 32 * 1, 32 * 32 * 1),\n",
    "#         )\n",
    "#         self.fc_weight_3 = nn.Sequential(\n",
    "#             nn.Linear(8 * 1 * 1, 16 * 1 * 1),\n",
    "#             ResidualBlock(16),\n",
    "#             nn.Linear(16 * 1 * 1, 24 * 1 * 1),\n",
    "#             ResidualBlock(24),\n",
    "#             nn.Linear(24 * 1 * 1, 32 * 1 * 1),\n",
    "#         )\n",
    "\n",
    "#         # For Bias Reconstruction\n",
    "#         self.fc_bias_1 = nn.Sequential(\n",
    "#             nn.Linear(8, 16),\n",
    "#             BiasResidualBlock(16),\n",
    "#             nn.Linear(16, 24),\n",
    "#             BiasResidualBlock(24),\n",
    "#             nn.Linear(24, 32),\n",
    "#         )\n",
    "#         self.fc_bias_2 = nn.Sequential(\n",
    "#             nn.Linear(8, 16),\n",
    "#             BiasResidualBlock(16),\n",
    "#             nn.Linear(16, 24),\n",
    "#             BiasResidualBlock(24),\n",
    "#             nn.Linear(24, 32),\n",
    "#         )\n",
    "#         self.fc_bias_3 = nn.Sequential(\n",
    "#             nn.Linear(1, 1),\n",
    "#             BiasResidualBlock(1),\n",
    "#             nn.Linear(1, 1),\n",
    "#         )\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Decode weight tensors\n",
    "#         weight_space = x[0]\n",
    "#         bias_space = x[1]\n",
    "#         new_weight_space = []\n",
    "\n",
    "#         # Flatten and apply linear layers for weight reconstruction\n",
    "#         weight1_flat = weight_space[0].view(weight_space[0].size(0), -1)  # Flatten\n",
    "#         new_weight_space.append(self.fc_weight_1(weight1_flat).view(weight_space[0].size(0), 2, 32, 1))\n",
    "\n",
    "#         weight2_flat = weight_space[1].view(weight_space[1].size(0), -1)\n",
    "#         weight2_intermediate = self.fc_weight_21(weight2_flat)\n",
    "#         new_weight_space.append(self.fc_weight_22(weight2_intermediate).view(weight_space[1].size(0), 32, 32, 1))\n",
    "\n",
    "#         weight3_flat = weight_space[2].view(weight_space[2].size(0), -1)\n",
    "#         new_weight_space.append(self.fc_weight_3(weight3_flat).view(weight_space[2].size(0), 32, 1, 1))\n",
    "\n",
    "#         new_bias_space = []\n",
    "#         # Decode bias tensors\n",
    "#         new_bias_space.append(self.fc_bias_1(bias_space[0].squeeze(-1)).view(-1, 32, 1))\n",
    "#         new_bias_space.append(self.fc_bias_2(bias_space[1].squeeze(-1)).view(-1, 32, 1))\n",
    "#         new_bias_space.append(self.fc_bias_3(bias_space[2].squeeze(-1)).view(-1, 1, 1))\n",
    "        \n",
    "#         return (tuple(new_weight_space), tuple(new_bias_space))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cd7dad00-ca7b-40dc-b81c-43afd4340956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class Decoder(nn.Module):\n",
    "#     def __init__(self, upsample_dim,\n",
    "#                  bias=True,\n",
    "#                  n_fc_layers=1,\n",
    "#                  num_heads=4):\n",
    "        \n",
    "#         super(Decoder, self).__init__()\n",
    "        \n",
    "#         self.fc_weight_1 = nn.Sequential(\n",
    "#             nn.Linear(32 * 2 * 1, 16 * 2 * 1),  # Assuming input size [batch, 8, 1, 1], adjust for your dimensions\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(16 * 2 * 1, 32 * 2 * 1),\n",
    "#         )\n",
    "        \n",
    "#         self.fc_weight_2 = nn.Sequential(\n",
    "#             nn.Linear(32 * 32 * 1, 16 * 32 * 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(16 * 32 * 1, 32 * 32 * 1),\n",
    "#         )\n",
    "#         self.fc_weight_3 = nn.Sequential(\n",
    "#             nn.Linear(32 * 1 * 1, 16 * 1 * 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(16 * 1 * 1, 32 * 1 * 1),\n",
    "#         )\n",
    "\n",
    "#         # For Bias Reconstruction\n",
    "#         self.fc_bias_1 = nn.Sequential(\n",
    "#             nn.Linear(32, 16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(16, 32),\n",
    "#         )\n",
    "#         self.fc_bias_2 = nn.Sequential(\n",
    "#             nn.Linear(32, 16),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(16, 32),\n",
    "#         )\n",
    "#         self.fc_bias_3 = nn.Sequential(\n",
    "#             nn.Linear(1, 1),\n",
    "#             nn.ReLU(),\n",
    "#             nn.Linear(1, 1),\n",
    "#         )\n",
    "        \n",
    "#         self.upsample_dim = upsample_dim\n",
    "#         self.bias = bias\n",
    "#         self.n_fc_layers = n_fc_layers\n",
    "#         self.num_heads = num_heads\n",
    "        \n",
    "#     def upsample_input_weights(self, inputs):\n",
    "#         \"\"\"Upsample the input weights to the specified dimensions.\"\"\"\n",
    "#         inputs = list(inputs)\n",
    "\n",
    "#         # Downsample first weight dimension [32,2,8,1] -> [32,2,32,1]\n",
    "#         inputs[0] = self._upsample_weight(inputs[0], dim=2 , index = 0)\n",
    "\n",
    "#         # Downsample second weight dimension [32,8,8,1] -> [32,32,32,1]\n",
    "#         inputs[1] = self._upsample_weight(inputs[1], dim=1, index = 1)\n",
    "#         inputs[1] = self._upsample_weight(inputs[1], dim=2, index = 1)\n",
    "\n",
    "\n",
    "#         # Downsample third weight dimension [32,8,1,1] -> [32,32,1,1]\n",
    "#         inputs[2] = self._upsample_weight(inputs[2], dim=1, index = 2)\n",
    "\n",
    "#         return tuple(inputs)\n",
    "\n",
    "#     def upsample_input_biases(self, inputs):\n",
    "#         \"\"\"Upsample the input biases to the specified dimensions.\"\"\"\n",
    "#         inputs = list(inputs)\n",
    "\n",
    "#         # Downsample first bias dimension [32,8,1] -> [32,32,1]\n",
    "#         inputs[0] = self._upsample_bias(inputs[0], index = 0)\n",
    "\n",
    "#         # Downsample second bias dimension [32,8,1] -> [32,32,1]\n",
    "#         inputs[1] = self._upsample_bias(inputs[1], index = 1)\n",
    "\n",
    "#         return tuple(inputs)\n",
    "    \n",
    "#     def _upsample_weight(self, weight, dim, index):\n",
    "#         d0 = weight.shape[dim]\n",
    "#         up_sample = GeneralSetLayer(\n",
    "#             in_features=d0,\n",
    "#             out_features=self.upsample_dim,\n",
    "#             reduction=\"attn\",\n",
    "#             bias=self.bias,\n",
    "#             n_fc_layers=self.n_fc_layers,\n",
    "#             num_heads=self.num_heads,\n",
    "#             set_layer=\"ds\",\n",
    "#         ).to(device)\n",
    "        \n",
    "#         wi = weight.permute(0, 3, 1, 2) if dim == 2 else weight.permute(0, 3, 2, 1)\n",
    "#         wi = up_sample(wi)\n",
    "#         wi = wi.permute(0, 2, 3, 1) if dim == 2 else wi.permute(0, 3, 2, 1)\n",
    "#         return wi \n",
    "\n",
    "#     def _upsample_bias(self, bias, index):\n",
    "#         d0 = bias.shape[1]\n",
    "#         up_sample = GeneralSetLayer(\n",
    "#             in_features=d0,\n",
    "#             out_features=self.upsample_dim,\n",
    "#             reduction=\"attn\",\n",
    "#             bias=self.bias,\n",
    "#             n_fc_layers=self.n_fc_layers,\n",
    "#             num_heads=self.num_heads,\n",
    "#             set_layer=\"ds\",\n",
    "#         ).to(device)\n",
    "        \n",
    "#         bi = bias.permute(0, 2, 1)\n",
    "#         bi = up_sample(bi)\n",
    "#         bi = bi.permute(0, 2, 1)\n",
    "#         return bi\n",
    "\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         # Decode weight tensors\n",
    "#         weight_space = self.upsample_input_weights(x[0])\n",
    "#         bias_space = self.upsample_input_biases(x[1])\n",
    "        \n",
    "#         # Process weight input 1 (32, 2, 32, 1)\n",
    "#         x1 = weight_space[0].view(weight_space[0].size(0), -1) \n",
    "#         x1 = self.fc_weight_1(x1)\n",
    "#         x1 = x1.view(weight_space[0].size())\n",
    "        \n",
    "#         # Process weight input 2 (32, 32, 32, 1)\n",
    "#         x2 = weight_space[1].view(weight_space[1].size(0), -1) \n",
    "#         x2 = self.fc_weight_2(x2)\n",
    "#         x2 = x2.view(weight_space[1].size())  # Output similar to (32, 32, 32, 1)\n",
    "        \n",
    "#         # Process weight input 3 (32, 32, 1, 1)\n",
    "#         x3 = weight_space[2].view(weight_space[2].size(0), -1) \n",
    "#         x3 = self.fc_weight_3(x3)\n",
    "#         x3 = x3.view(weight_space[2].size())  # Output similar to (32, 32, 1, 1)\n",
    "        \n",
    "#         # Process bias input 1 (32, 32, 1)\n",
    "#         b1 = bias_space[0].view(bias_space[0].size(0), -1)  # Flatten (32, 32, 1) to (32, 32)\n",
    "#         b1 = self.fc_bias_1(b1)\n",
    "#         b1 = b1.view(bias_space[0].size())  # Reshape back to (32, 32, 1)\n",
    "        \n",
    "#         # Process bias input 2 (32, 1, 1)\n",
    "#         b2 = bias_space[1].view(bias_space[1].size(0), -1)  # Flatten (32, 32, 1) to (32, 32)\n",
    "#         b2 = self.fc_bias_2(b2)\n",
    "#         b2 = b2.view(bias_space[1].size())  # Reshape back to (32, 1, 1)\n",
    "        \n",
    "#         # Process bias input 3 (32, 1, 1)\n",
    "#         b3 = bias_space[2].view(bias_space[2].size(0), -1)  # Flatten (32, 1, 1) to (32, 1)\n",
    "#         b3 = self.fc_bias_3(b3)  # Using the same fc2 layer as bias_input2, or define another if needed\n",
    "#         b3 = b3.view(bias_space[2].size())  # Reshape back to (32, 1, 1)\n",
    "        \n",
    "#         new_weight_space = (x1, x2, x3)\n",
    "#         new_bias_space = (b1, b2, b3)\n",
    "\n",
    "#         return (new_weight_space, new_bias_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb25dad2-1870-4839-877d-61081f4f294a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class Decoder(nn.Module,\n",
    "             ):\n",
    "    def __init__(self, upsample_dim,\n",
    "                weight_shapes,\n",
    "                bias_shapes,\n",
    "                input_features,\n",
    "                hidden_dims,\n",
    "                downsample_dim,\n",
    "                n_hidden=2,\n",
    "                reduction=\"max\",\n",
    "                set_layer=\"sab\",\n",
    "                add_layer_skip=False,\n",
    "                input_dim_downsample=None,\n",
    "                init_scale=1.,\n",
    "                init_off_diag_scale_penalty=1.,\n",
    "                bn=False,\n",
    "                dropout_rate = 0.001,\n",
    "                diagonal=False,\n",
    "                 bias=True,\n",
    "                 n_fc_layers=1,\n",
    "                 num_heads=4):\n",
    "        \n",
    "        super(Decoder, self).__init__()\n",
    "        \n",
    "        self.fc_weight_1 = nn.Sequential(\n",
    "            nn.Linear(32 * 2 * 1, 16 * 2 * 1),  # Assuming input size [batch, 8, 1, 1], adjust for your dimensions\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16 * 2 * 1, 32 * 2 * 1),\n",
    "        )\n",
    "        \n",
    "        self.fc_weight_2 = nn.Sequential(\n",
    "            nn.Linear(32 * 32 * 1, 16 * 32 * 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16 * 32 * 1, 32 * 32 * 1),\n",
    "        )\n",
    "        self.fc_weight_3 = nn.Sequential(\n",
    "            nn.Linear(32 * 1 * 1, 16 * 1 * 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16 * 1 * 1, 32 * 1 * 1),\n",
    "        )\n",
    "\n",
    "        # For Bias Reconstruction\n",
    "        self.fc_bias_1 = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "        )\n",
    "        self.fc_bias_2 = nn.Sequential(\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16, 32),\n",
    "        )\n",
    "        self.fc_bias_3 = nn.Sequential(\n",
    "            nn.Linear(1, 1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1, 1),\n",
    "        )\n",
    "        \n",
    "        self.upsample_dim = upsample_dim\n",
    "        self.bias = bias\n",
    "        self.n_fc_layers = n_fc_layers\n",
    "        self.num_heads = num_heads\n",
    "        \n",
    "        self.InitialLayer = DWSModel(\n",
    "            weight_shapes= weight_shapes,\n",
    "            bias_shapes= bias_shapes,\n",
    "            input_features=input_features,\n",
    "            hidden_dim=hidden_dims,\n",
    "            n_hidden=n_hidden,\n",
    "            reduction=reduction,\n",
    "            bias=bias,\n",
    "            output_features=input_features,\n",
    "            n_fc_layers=n_fc_layers,\n",
    "            num_heads=num_heads,\n",
    "            set_layer=set_layer,\n",
    "            dropout_rate=dropout_rate,\n",
    "            input_dim_downsample=input_dim_downsample,\n",
    "            init_scale=init_scale,\n",
    "            init_off_diag_scale_penalty=init_off_diag_scale_penalty,\n",
    "            bn=bn,\n",
    "            add_skip=False,\n",
    "            add_layer_skip=add_layer_skip,\n",
    "            diagonal=diagonal,\n",
    "        )   \n",
    "        \n",
    "    def upsample_input_weights(self, inputs):\n",
    "        \"\"\"Upsample the input weights to the specified dimensions.\"\"\"\n",
    "        inputs = list(inputs)\n",
    "\n",
    "        # Downsample first weight dimension [32,2,8,1] -> [32,2,32,1]\n",
    "        inputs[0] = self._upsample_weight(inputs[0], dim=2 , index = 0)\n",
    "\n",
    "        # Downsample second weight dimension [32,8,8,1] -> [32,32,32,1]\n",
    "        inputs[1] = self._upsample_weight(inputs[1], dim=1, index = 1)\n",
    "        inputs[1] = self._upsample_weight(inputs[1], dim=2, index = 1)\n",
    "\n",
    "\n",
    "        # Downsample third weight dimension [32,8,1,1] -> [32,32,1,1]\n",
    "        inputs[2] = self._upsample_weight(inputs[2], dim=1, index = 2)\n",
    "\n",
    "        return tuple(inputs)\n",
    "\n",
    "    def upsample_input_biases(self, inputs):\n",
    "        \"\"\"Upsample the input biases to the specified dimensions.\"\"\"\n",
    "        inputs = list(inputs)\n",
    "\n",
    "        # Downsample first bias dimension [32,8,1] -> [32,32,1]\n",
    "        inputs[0] = self._upsample_bias(inputs[0], index = 0)\n",
    "\n",
    "        # Downsample second bias dimension [32,8,1] -> [32,32,1]\n",
    "        inputs[1] = self._upsample_bias(inputs[1], index = 1)\n",
    "\n",
    "        return tuple(inputs)\n",
    "    \n",
    "    def _upsample_weight(self, weight, dim, index):\n",
    "        d0 = weight.shape[dim]\n",
    "        up_sample = GeneralSetLayer(\n",
    "            in_features=d0,\n",
    "            out_features=self.upsample_dim,\n",
    "            reduction=\"attn\",\n",
    "            bias=self.bias,\n",
    "            n_fc_layers=self.n_fc_layers,\n",
    "            num_heads=self.num_heads,\n",
    "            set_layer=\"ds\",\n",
    "        ).to(device)\n",
    "        \n",
    "        wi = weight.permute(0, 3, 1, 2) if dim == 2 else weight.permute(0, 3, 2, 1)\n",
    "        wi = up_sample(wi)\n",
    "        wi = wi.permute(0, 2, 3, 1) if dim == 2 else wi.permute(0, 3, 2, 1)\n",
    "        return wi \n",
    "\n",
    "    def _upsample_bias(self, bias, index):\n",
    "        d0 = bias.shape[1]\n",
    "        up_sample = GeneralSetLayer(\n",
    "            in_features=d0,\n",
    "            out_features=self.upsample_dim,\n",
    "            reduction=\"attn\",\n",
    "            bias=self.bias,\n",
    "            n_fc_layers=self.n_fc_layers,\n",
    "            num_heads=self.num_heads,\n",
    "            set_layer=\"ds\",\n",
    "        ).to(device)\n",
    "        \n",
    "        bi = bias.permute(0, 2, 1)\n",
    "        bi = up_sample(bi)\n",
    "        bi = bi.permute(0, 2, 1)\n",
    "        return bi\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Decode weight tensors\n",
    "        weight_space = self.upsample_input_weights(x[0])\n",
    "        bias_space = self.upsample_input_biases(x[1])\n",
    "\n",
    "        output = self.InitialLayer((weight_space , bias_space))\n",
    "        # Process weight input 1 (32, 2, 32, 1)\n",
    "#         x1 = weight_space[0].reshape(weight_space[0].size(0), -1) \n",
    "#         x1 = self.fc_weight_1(x1)\n",
    "#         x1 = x1.reshape(weight_space[0].size())\n",
    "        \n",
    "#         # Process weight input 2 (32, 32, 32, 1)\n",
    "#         x2 = weight_space[1].reshape(weight_space[1].size(0), -1) \n",
    "#         x2 = self.fc_weight_2(x2)\n",
    "#         x2 = x2.reshape(weight_space[1].size())  # Output similar to (32, 32, 32, 1)\n",
    "        \n",
    "#         # Process weight input 3 (32, 32, 1, 1)\n",
    "#         x3 = weight_space[2].reshape(weight_space[2].size(0), -1) \n",
    "#         x3 = self.fc_weight_3(x3)\n",
    "#         x3 = x3.reshape(weight_space[2].size())  # Output similar to (32, 32, 1, 1)\n",
    "        \n",
    "#         # Process bias input 1 (32, 32, 1)\n",
    "#         b1 = bias_space[0].reshape(bias_space[0].size(0), -1)  # Flatten (32, 32, 1) to (32, 32)\n",
    "#         b1 = self.fc_bias_1(b1)\n",
    "#         b1 = b1.reshape(bias_space[0].size())  # Reshape back to (32, 32, 1)\n",
    "        \n",
    "#         # Process bias input 2 (32, 1, 1)\n",
    "#         b2 = bias_space[1].reshape(bias_space[1].size(0), -1)  # Flatten (32, 32, 1) to (32, 32)\n",
    "#         b2 = self.fc_bias_2(b2)\n",
    "#         b2 = b2.reshape(bias_space[1].size())  # Reshape back to (32, 1, 1)\n",
    "        \n",
    "#         # Process bias input 3 (32, 1, 1)\n",
    "#         b3 = bias_space[2].reshape(bias_space[2].size(0), -1)  # Flatten (32, 1, 1) to (32, 1)\n",
    "#         b3 = self.fc_bias_3(b3)  # Using the same fc2 layer as bias_input2, or define another if needed\n",
    "#         b3 = b3.reshape(bias_space[2].size())  # Reshape back to (32, 1, 1)\n",
    "        \n",
    "#         new_weight_space = (x1, x2, x3)\n",
    "#         new_bias_space = (b1, b2, b3)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "03cc6e4a-fb7b-4036-8521-7e17a5a0d8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our AutoEncoder using DWSModel\n",
    "import numpy as np\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self,\n",
    "            input_features,\n",
    "            weight_shapes,\n",
    "            bias_shapes,\n",
    "            hidden_dims,\n",
    "            downsample_dim,\n",
    "            n_hidden=2,\n",
    "            reduction = \"attn\",\n",
    "            input_dim_downsample=None,\n",
    "            bn = False,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.encoder = DWSEncoder(weight_shapes=weight_shapes,\n",
    "                                bias_shapes=bias_shapes,\n",
    "                                input_features=input_features,\n",
    "                                hidden_dims=hidden_dims,\n",
    "                                downsample_dim = downsample_dim,\n",
    "                                n_hidden=n_hidden,\n",
    "                                reduction= reduction,\n",
    "                                bn=bn).to(device)\n",
    "        self.decoder = Decoder(upsample_dim= 32,weight_shapes=weight_shapes,\n",
    "                                bias_shapes=bias_shapes,\n",
    "                                input_features=input_features,\n",
    "                                hidden_dims=hidden_dims,\n",
    "                                downsample_dim = downsample_dim,\n",
    "                                n_hidden=n_hidden,\n",
    "                                reduction= reduction,\n",
    "                                bn=bn).to(device)\n",
    "        \n",
    "    def forward(self,inputs):\n",
    "        encoded_data = self.encoder(inputs)\n",
    "        output = self.decoder(encoded_data)\n",
    "        return encoded_data,output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3a50c50-58d3-4130-8212-0d3e53f13eb6",
   "metadata": {},
   "source": [
    "Training MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74a63092-77d2-4459-8803-3a0b7a8ebda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# @torch.no_grad()\n",
    "# def evaluate(model, loader):\n",
    "#     model.eval()\n",
    "#     loss = 0.0\n",
    "#     correct = 0.0\n",
    "#     total = 0.0\n",
    "#     predicted, gt = [], []\n",
    "#     for batch in loader:\n",
    "#         batch = batch.to(device)\n",
    "#         inputs = (batch.weights, batch.biases)\n",
    "#         out = model(inputs)\n",
    "#         loss += F.cross_entropy(out, batch.label, reduction=\"sum\")\n",
    "#         total += len(batch.label)\n",
    "#         pred = out.argmax(1)\n",
    "#         correct += pred.eq(batch.label).sum()\n",
    "#         predicted.extend(pred.cpu().numpy().tolist())\n",
    "#         gt.extend(batch.label.cpu().numpy().tolist())\n",
    "\n",
    "#     model.train()\n",
    "#     avg_loss = loss / total\n",
    "#     avg_acc = correct / total\n",
    "\n",
    "#     return dict(avg_loss=avg_loss, avg_acc=avg_acc, predicted=predicted, gt=gt)\n",
    "\n",
    "# model = AutoEncoder(\n",
    "#     input_features=1,\n",
    "#     weight_shapes = weight_shapes, \n",
    "#     bias_shapes = bias_shapes,\n",
    "#     downsample_dim = 8,\n",
    "#     hidden_dims=32,\n",
    "#     reduction = \"max\",\n",
    "#     n_hidden=8,\n",
    "#     bn=False,\n",
    "# ).to(device)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(params=model.parameters(), lr=1e-3, amsgrad=True, weight_decay=5e-4)\n",
    "# epochs = 5\n",
    "\n",
    "# epoch_iter = trange(epochs)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# for epoch in epoch_iter:\n",
    "#     for i, batch in enumerate(train_loader):\n",
    "#         model.train()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         batch = batch.to(device)\n",
    "#         inputs = (batch.weights, batch.biases)\n",
    "#         out = model(inputs)\n",
    "\n",
    "#         loss = criterion(out, batch.label)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_iter.set_description(  \n",
    "#             f\"[{epoch} {i+1}], train loss: {loss.item():.3f}\"\n",
    "#         )\n",
    "#     test_loss_dict = evaluate(model, test_loader)\n",
    "#     test_acc = test_loss_dict['avg_acc'].item()\n",
    "#     print(f\"test accuracy:{test_acc:.4f}\")\n",
    "#     torch.save(model.state_dict(), f\"Outputs/model_epoch_{epoch}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9b38af-7804-42dc-96a7-0925c774504d",
   "metadata": {},
   "source": [
    "Training Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f6eb3634-b1d5-4d1e-8edc-8f21aadc1e9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinkhorn_loss(preds, targets, epsilon=0.1, num_iters=100):\n",
    "   \n",
    "    # Determine the dimensions of preds and targets\n",
    "    preds_dims = preds.dim()\n",
    "    targets_dims = targets.dim()\n",
    "    \n",
    "    if preds_dims == 4:  # preds is of shape (batch_size, n_sets, n_points_pred, dim)\n",
    "        batch_size, n_sets, n_points_pred, _ = preds.shape\n",
    "        n_points_target = targets.shape[2]\n",
    "        \n",
    "        # Compute the pairwise distance matrix (cost_matrix) between preds and targets\n",
    "        cost_matrix = torch.cdist(preds.reshape(batch_size * n_sets, n_points_pred, -1), \n",
    "                                   targets.reshape(batch_size * n_sets, n_points_target, -1), \n",
    "                                   p=2).reshape(batch_size, n_sets, n_points_pred, n_points_target)\n",
    "\n",
    "        # Initialize uniform marginals for both distributions\n",
    "        mu = torch.full((batch_size, n_sets, n_points_pred), 1.0 / n_points_pred, device=preds.device)\n",
    "        nu = torch.full((batch_size, n_sets, n_points_target), 1.0 / n_points_target, device=targets.device)\n",
    "        \n",
    "    elif preds_dims == 3:  # preds is of shape (batch_size, n_points_pred, dim)\n",
    "        batch_size, n_points_pred, _ = preds.shape\n",
    "        n_points_target = targets.shape[1]\n",
    "        \n",
    "        # Compute the pairwise distance matrix (cost_matrix) between preds and targets\n",
    "        cost_matrix = torch.cdist(preds.reshape(batch_size, n_points_pred, -1), \n",
    "                                   targets.reshape(batch_size, n_points_target, -1), \n",
    "                                   p=2).reshape(batch_size, 1, n_points_pred, n_points_target)\n",
    "\n",
    "        # Initialize uniform marginals for both distributions\n",
    "        mu = torch.full((batch_size, 1, n_points_pred), 1.0 / n_points_pred, device=preds.device)\n",
    "        nu = torch.full((batch_size, 1, n_points_target), 1.0 / n_points_target, device=targets.device)\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(\"Input tensors must be either 3D or 4D.\")\n",
    "\n",
    "    # Initialize dual variables (log scale to ensure positivity)\n",
    "    u = torch.zeros_like(mu)\n",
    "    v = torch.zeros_like(nu)\n",
    "\n",
    "    # Perform Sinkhorn iterations\n",
    "    for _ in range(num_iters):\n",
    "        u = epsilon * (torch.log(mu + 1e-8) - torch.logsumexp(-cost_matrix / epsilon + v.unsqueeze(-2), dim=-1))\n",
    "        v = epsilon * (torch.log(nu + 1e-8) - torch.logsumexp(-cost_matrix / epsilon + u.unsqueeze(-1), dim=-2))\n",
    "\n",
    "    # Compute the optimal transport cost\n",
    "    transport_plan = torch.exp((-cost_matrix + u.unsqueeze(-1) + v.unsqueeze(-2)) / epsilon)\n",
    "    loss = torch.sum(transport_plan * cost_matrix, dim=[2, 3]).mean()\n",
    "    \n",
    "    return loss\n",
    "\n",
    "# Chamfer Loss implementation\n",
    "def chamfer_loss(x, y):\n",
    "    x = x.unsqueeze(1)  # (n, 1, d)\n",
    "    y = y.unsqueeze(0)  # (1, m, d)\n",
    "\n",
    "    dist = torch.norm(x - y, dim=2)  # Shape (n, m)\n",
    "\n",
    "    min_dist_x = dist.min(dim=1)[0]  # Min distance for each point in x\n",
    "    min_dist_y = dist.min(dim=0)[0]  # Min distance for each point in y\n",
    "\n",
    "    loss = min_dist_x.mean() + min_dist_y.mean()\n",
    "    return loss\n",
    "\n",
    "# Set Mean Squared Error implementation\n",
    "def set_mse_loss(x, y):\n",
    "    x_expanded = x.unsqueeze(1)  # (n, 1, d)\n",
    "    y_expanded = y.unsqueeze(0)  # (1, m, d)\n",
    "\n",
    "    squared_diff = (x_expanded - y_expanded) ** 2  # Shape (n, m, d)\n",
    "\n",
    "    mse = squared_diff.mean(dim=-1)  # Shape (n, m)\n",
    "\n",
    "    min_mse_x = mse.min(dim=1)[0]  # Min MSE for each point in x\n",
    "    min_mse_y = mse.min(dim=0)[0]  # Min MSE for each point in y\n",
    "\n",
    "    loss = (min_mse_x.mean() + min_mse_y.mean()) / 2\n",
    "    return loss\n",
    "\n",
    "def hungarian_loss(preds, targets):\n",
    "    # Calculate the cost matrix (L2 distance between preds and targets)\n",
    "    cost_matrix = torch.cdist(preds.unsqueeze(1), targets.unsqueeze(1), p=2).squeeze(1)\n",
    "\n",
    "    # Solve the assignment problem\n",
    "    row_ind, col_ind = torch.min(cost_matrix, dim=1)\n",
    "\n",
    "    # Ensure indices are long tensors (required for indexing)\n",
    "    row_ind = row_ind.long()\n",
    "    col_ind = col_ind.long()\n",
    "\n",
    "    # Calculate the total loss\n",
    "    loss = cost_matrix[row_ind, col_ind].mean()\n",
    "\n",
    "    return loss\n",
    "\n",
    "\n",
    "def rotation_matrix(theta):\n",
    "    \"\"\"\n",
    "    Create a 2D rotation matrix for a given angle theta (in radians).\n",
    "    theta: float or tensor\n",
    "    Returns a 2x2 tensor rotation matrix.\n",
    "    \"\"\"\n",
    "    theta_tensor = torch.tensor(theta)  # Convert theta to tensor\n",
    "    return torch.tensor([\n",
    "        [torch.cos(theta_tensor), -torch.sin(theta_tensor)],\n",
    "        [torch.sin(theta_tensor), torch.cos(theta_tensor)]\n",
    "    ])\n",
    "\n",
    "# Define the MSE loss with rotation\n",
    "def mse_loss_with_rotation(x, y, num_rotations=36):\n",
    "    \"\"\"\n",
    "    Compute the MSE reconstruction loss with discrete rotations applied.\n",
    "    \n",
    "    Args:\n",
    "    - x (torch.Tensor): Original input sample (e.g., MNIST image).\n",
    "    - y (torch.Tensor): Reconstructed output from the autoencoder.\n",
    "    - num_rotations (int): Number of discrete rotations to consider (e.g., 36 means 10-degree steps).\n",
    "    \n",
    "    Returns:\n",
    "    - loss (torch.Tensor): The minimum MSE loss across all rotations.\n",
    "    \"\"\"\n",
    "    batch_size = x.size(0)\n",
    "    \n",
    "    # Initialize the minimum MSE as a large value\n",
    "    min_mse = torch.full((batch_size,), float('inf'), device=x.device)\n",
    "    \n",
    "    for i in range(num_rotations):\n",
    "        # Compute the rotation angle (in radians)\n",
    "        theta = i * (2 * torch.pi / num_rotations)\n",
    "        \n",
    "        # Apply rotation to the reconstructed output y\n",
    "        rot_matrix = rotation_matrix(theta).to(x.device)\n",
    "        \n",
    "        # Assume inputs have at least two dimensions (for rotation)\n",
    "        if len(y.shape) >= 3 and y.shape[-1] == 2:  # Check if it's a 2D vector\n",
    "            y_rot = torch.einsum('ij,bjk->bik', rot_matrix, y)  # Apply rotation to each sample\n",
    "        else:\n",
    "            # Skip rotation if it's not a 2D vector\n",
    "            y_rot = y\n",
    "        \n",
    "        # Compute the MSE loss between the original input x and the rotated reconstruction y_rot\n",
    "        mse = F.mse_loss(x, y_rot, reduction='none').mean(dim=[1])  # Mean over spatial dimensions\n",
    "        \n",
    "        # Track the minimum MSE over all rotations\n",
    "        min_mse = torch.min(min_mse, mse)\n",
    "    \n",
    "    return min_mse.mean()\n",
    "\n",
    "# Custom loss function for tuples of tensors\n",
    "class TupleLoss(nn.Module):\n",
    "    def __init__(self, loss_type='hungarian_loss'):\n",
    "        super(TupleLoss, self).__init__()\n",
    "        self.loss_type = loss_type  # Type of loss to compute\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        weights1, biases1 = output\n",
    "        weights2, biases2 = target\n",
    "\n",
    "        # Calculate weight loss\n",
    "        weight_loss = torch.mean(torch.stack(\n",
    "            [self._calculate_loss(w1, w2) for w1, w2 in zip(weights1, weights2)]\n",
    "        ))\n",
    "\n",
    "        # Calculate bias loss\n",
    "        bias_loss = torch.mean(torch.stack(\n",
    "            [self._calculate_loss(b1, b2) for b1, b2 in zip(biases1, biases2)]\n",
    "        ))\n",
    "\n",
    "        # Total loss calculation\n",
    "        total_loss = 0.5 * weight_loss + 0.5 * bias_loss\n",
    "        return total_loss\n",
    "\n",
    "    def _calculate_loss(self, w1, w2):\n",
    "        # Calculate weight loss based on the specified loss type\n",
    "        if self.loss_type == 'chamfer':\n",
    "            return chamfer_loss(w1, w2)\n",
    "        elif self.loss_type == 'sinkhorn':\n",
    "            return sinkhorn_loss(w1, w2)\n",
    "        elif self.loss_type == 'set_mse':\n",
    "            return set_mse_loss(w1, w2)\n",
    "        elif self.loss_type == 'hungarian':\n",
    "            return hungarian_loss(w1, w2)\n",
    "        elif self.loss_type == 'mse_loss_with_rotation':\n",
    "            return mse_loss_with_rotation(w1,w2)\n",
    "        else:\n",
    "            raise ValueError(\"Invalid loss type specified\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8dbb9035-531c-4ed3-9f40-8f1bd61a29b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.nn.functional as F\n",
    "\n",
    "# class TupleCosineLoss(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(TupleCosineLoss, self).__init__()\n",
    "\n",
    "#     def forward(self, output, target):\n",
    "#         weights1, biases1 = output\n",
    "#         weights2, biases2 = target\n",
    "\n",
    "#         # Compute cosine similarity for weights\n",
    "#         weight_loss = [1 - F.cosine_similarity(w1.reshape(1, -1), w2.reshape(1, -1), dim=1) for w1, w2 in zip(weights1, weights2)]\n",
    "#         weight_loss = torch.mean(torch.stack(weight_loss))\n",
    "        \n",
    "#         # Compute cosine similarity for biases\n",
    "#         bias_loss = [1 - F.cosine_similarity(b1.reshape(1, -1), b2.reshape(1, -1), dim=1) for b1, b2 in zip(biases1, biases2)]\n",
    "#         bias_loss = torch.mean(torch.stack(bias_loss))\n",
    "                \n",
    "#         # Combine the losses\n",
    "#         total_loss = 0.5 * weight_loss + 0.5 * bias_loss\n",
    "        \n",
    "#         return total_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ec5bfd49-9f3d-4506-8b99-e1a98845f5c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.manifold import TSNE\n",
    "\n",
    "# def plot_tsne(inputs, out):\n",
    "#     weights_out, biases_out = out[0], out[1]\n",
    "#     weights_inputs, biases_inputs = inputs[0], inputs[1]\n",
    "\n",
    "#     # Function to flatten and pad data to ensure consistent dimensions\n",
    "#     def flatten_and_pad(data):\n",
    "#         max_length = max(len(d.cpu().detach().flatten().numpy()) for d in data)\n",
    "#         return [np.pad(d.cpu().detach().flatten().numpy(), (0, max_length - len(d.cpu().detach().flatten().numpy())), 'constant') for d in data]\n",
    "\n",
    "#     # Flattening and padding weights and biases for outputs and inputs\n",
    "#     flattened_weights_out = flatten_and_pad(weights_out)\n",
    "#     flattened_biases_out = flatten_and_pad(biases_out)\n",
    "#     flattened_weights_inputs = flatten_and_pad(weights_inputs)\n",
    "#     flattened_biases_inputs = flatten_and_pad(biases_inputs)\n",
    "\n",
    "#     # Combining weights and biases\n",
    "#     combined_data_out = [np.concatenate([w, b]) for w, b in zip(flattened_weights_out, flattened_biases_out)]\n",
    "#     combined_data_inputs = [np.concatenate([w, b]) for w, b in zip(flattened_weights_inputs, flattened_biases_inputs)]\n",
    "\n",
    "#     # Ensure all combined data has the same length\n",
    "#     max_length = max(len(d) for d in combined_data_out + combined_data_inputs)\n",
    "#     combined_data_out = [np.pad(d, (0, max_length - len(d)), 'constant') for d in combined_data_out]\n",
    "#     combined_data_inputs = [np.pad(d, (0, max_length - len(d)), 'constant') for d in combined_data_inputs]\n",
    "\n",
    "#     # Combine both inputs and outputs for t-SNE\n",
    "#     combined_data = np.vstack([combined_data_inputs, combined_data_out])\n",
    "\n",
    "#     # Applying t-SNE\n",
    "#     tsne = TSNE(n_components=2, random_state=0)\n",
    "#     tsne_results = tsne.fit_transform(combined_data)\n",
    "\n",
    "#     # Split results back into inputs and outputs\n",
    "#     tsne_results_inputs = tsne_results[:len(combined_data_inputs)]\n",
    "#     tsne_results_out = tsne_results[len(combined_data_inputs):]\n",
    "\n",
    "#     # Plotting\n",
    "#     plt.figure(figsize=(10, 6))\n",
    "    \n",
    "#     # Plot t-SNE results for outputs\n",
    "#     plt.scatter(tsne_results_out[:, 0], tsne_results_out[:, 1], label='Outputs', marker='o')\n",
    "    \n",
    "#     # Plot t-SNE results for inputs\n",
    "#     plt.scatter(tsne_results_inputs[:, 0], tsne_results_inputs[:, 1], label='Inputs', marker='x')\n",
    "\n",
    "#     # Adding titles and labels\n",
    "#     plt.title('t-SNE of Combined Weights and Biases')\n",
    "#     plt.xlabel('t-SNE Dimension 1')\n",
    "#     plt.ylabel('t-SNE Dimension 2')\n",
    "#     plt.legend()\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "483e4810-56f0-4f47-a342-f2c7040787bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def evaluate(model, loader):\n",
    "    model.eval()\n",
    "    loss = 0.0\n",
    "    total = 0.0\n",
    "    criterion = TupleLoss(loss_type='mse_loss_with_rotation')\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        inputs = (batch.weights, batch.biases)\n",
    "        _,out = model(inputs)\n",
    "        loss += criterion(out, inputs)\n",
    "        total += 1\n",
    "\n",
    "    model.train()\n",
    "    avg_loss = loss / total\n",
    "\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4f8994a5-e1d3-4844-935a-b7eb739b0ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import torch\n",
    "from tqdm import trange\n",
    "    \n",
    "def train_model(model):\n",
    "    learning_rate = 1e-3\n",
    "    num_epochs = 500\n",
    "    criterion = TupleLoss(loss_type='mse_loss_with_rotation') \n",
    "    epoch_iter = trange(num_epochs)\n",
    "    epoch_loss = -1\n",
    "    \n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.01, patience=5)\n",
    "    previous_epoch_loss = 1000\n",
    "\n",
    "    for epoch in epoch_iter:\n",
    "        total_loss = 0\n",
    "        counter = 0\n",
    "        \n",
    "        for i, batch in enumerate(train_loader):\n",
    "            model.train() \n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch = batch.to(device)\n",
    "            inputs = (batch.weights, batch.biases)\n",
    "            _,out = model(inputs)\n",
    "\n",
    "            loss = criterion(out, inputs)\n",
    "            \n",
    "            loss.backward()\n",
    "            optimizer.step() \n",
    "\n",
    "            total_loss += loss.item()\n",
    "            counter += 1\n",
    "\n",
    "            epoch_iter.set_description(\n",
    "                f\"[{epoch} {i+1}], train loss: {loss.item():.5f}, epoch loss: {epoch_loss:.5f}\"\n",
    "            )\n",
    "            \n",
    "            \n",
    "        epoch_loss = total_loss / counter\n",
    "\n",
    "        scheduler.step(epoch_loss)\n",
    "            \n",
    "        if epoch_loss<previous_epoch_loss:\n",
    "            model_path = f\"Outputs/model_epoch_withSkip_mse_loss_with_rotation.pth\"\n",
    "            torch.save(model.state_dict(), model_path)\n",
    "            previous_epoch_loss = epoch_loss\n",
    "            \n",
    "        if (epoch+1)%25 == 0:\n",
    "             print(evaluate(model, test_loader))\n",
    "\n",
    "    print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ff974152-65f1-447c-90db-3a794c464a38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-85871aefa6c7>:26: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load('Outputs/model_epoch_withSkip_mse_loss_with_rotation.pth'))\n",
      "  0%|          | 0/500 [00:00<?, ?it/s]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[0 860], train loss: 0.91432, epoch loss: -1.00000:   0%|          | 1/500 [21:06<175:33:28, 1266.55s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[1 860], train loss: 0.85289, epoch loss: 0.87045:   0%|          | 2/500 [42:26<176:19:04, 1274.59s/it] /work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[2 860], train loss: 0.87111, epoch loss: 0.87043:   1%|          | 3/500 [57:53<154:00:33, 1115.56s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[3 860], train loss: 0.90349, epoch loss: 0.86996:   1%|          | 4/500 [1:16:21<153:19:55, 1112.89s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[4 860], train loss: 0.88675, epoch loss: 0.87010:   1%|          | 5/500 [1:32:08<144:45:32, 1052.79s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[5 860], train loss: 0.89336, epoch loss: 0.87001:   1%|          | 6/500 [1:53:42<155:45:20, 1135.06s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[6 860], train loss: 0.84286, epoch loss: 0.86962:   1%|▏         | 7/500 [2:15:20<162:41:53, 1188.06s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[7 860], train loss: 0.89484, epoch loss: 0.86987:   2%|▏         | 8/500 [2:36:54<166:59:50, 1221.93s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[8 860], train loss: 0.84702, epoch loss: 0.86939:   2%|▏         | 9/500 [2:58:30<169:50:00, 1245.21s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[9 860], train loss: 0.87409, epoch loss: 0.86925:   2%|▏         | 10/500 [3:20:02<171:27:22, 1259.68s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[10 860], train loss: 0.90132, epoch loss: 0.86958:   2%|▏         | 11/500 [3:41:37<172:32:22, 1270.23s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[11 860], train loss: 0.86011, epoch loss: 0.86959:   2%|▏         | 12/500 [4:03:09<173:07:03, 1277.10s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[12 860], train loss: 0.88558, epoch loss: 0.86929:   3%|▎         | 13/500 [4:17:50<156:29:37, 1156.83s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[13 860], train loss: 0.86195, epoch loss: 0.86948:   3%|▎         | 14/500 [4:27:12<131:54:57, 977.16s/it] /work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[14 860], train loss: 0.91145, epoch loss: 0.86882:   3%|▎         | 15/500 [4:36:31<114:40:46, 851.23s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[15 860], train loss: 0.85598, epoch loss: 0.86834:   3%|▎         | 16/500 [4:45:50<102:36:31, 763.21s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[16 860], train loss: 0.85506, epoch loss: 0.86782:   3%|▎         | 17/500 [4:55:11<94:14:35, 702.43s/it] /work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[17 860], train loss: 0.81214, epoch loss: 0.86807:   4%|▎         | 18/500 [5:04:32<88:21:51, 659.98s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[18 860], train loss: 0.86636, epoch loss: 0.86784:   4%|▍         | 19/500 [5:23:36<107:37:28, 805.51s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[19 73], train loss: 0.85056, epoch loss: 0.86843:   4%|▍         | 19/500 [5:25:27<137:19:13, 1027.76s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-85871aefa6c7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Outputs/model_epoch_withSkip_mse_loss_with_rotation.pth'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-22-8ef34a9521d2>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1553\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1560\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1561\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1564\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-bfb3bbf1ff8c>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, output, target)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# Calculate weight loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         weight_loss = torch.mean(torch.stack(\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         ))\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-bfb3bbf1ff8c>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    158\u001b[0m         \u001b[0;31m# Calculate weight loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m         weight_loss = torch.mean(torch.stack(\n\u001b[0;32m--> 160\u001b[0;31m             \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_calculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m         ))\n\u001b[1;32m    162\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-bfb3bbf1ff8c>\u001b[0m in \u001b[0;36m_calculate_loss\u001b[0;34m(self, w1, w2)\u001b[0m\n\u001b[1;32m    181\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhungarian_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mse_loss_with_rotation'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmse_loss_with_rotation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid loss type specified\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-18-bfb3bbf1ff8c>\u001b[0m in \u001b[0;36mmse_loss_with_rotation\u001b[0;34m(x, y, num_rotations)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[0;31m# Apply rotation to the reconstructed output y\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0mrot_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrotation_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtheta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0;31m# Assume inputs have at least two dimensions (for rotation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# #Model with DWS DownSample Layers\n",
    "weight_shapes = tuple(w.shape[:2] for w in point.weights)\n",
    "bias_shapes = tuple(b.shape[:1] for b in point.biases)\n",
    "\n",
    "model = AutoEncoder(\n",
    "    input_features=1,\n",
    "    weight_shapes = weight_shapes, \n",
    "    bias_shapes = bias_shapes,\n",
    "    downsample_dim = 8,\n",
    "    hidden_dims=32,\n",
    "    reduction = \"max\",\n",
    "    n_hidden=4,\n",
    "    bn=True,\n",
    ").to(device)\n",
    "\n",
    "\n",
    "# for name, param in model.named_parameters():\n",
    "#     if param.dim() >= 2:  # Initialize weights (only for tensors with 2 or more dimensions)\n",
    "#         # Initialize convolutional layer weights using Kaiming normal initialization\n",
    "#         if 'conv' in name and 'weight' in name:\n",
    "#             nn.init.kaiming_normal_(param)\n",
    "#         # Initialize linear layer weights using Xavier uniform initialization\n",
    "#         elif 'fc' in name and 'weight' in name:\n",
    "#             nn.init.xavier_uniform_(param)\n",
    "\n",
    "model.load_state_dict(torch.load('Outputs/model_epoch_withSkip_mse_loss_with_rotation.pth'))\n",
    "train_model(model)\n",
    "print(evaluate(model, train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "64c72ca9-d62c-4afb-b0a3-ddd6bede0ffd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy: 10.09%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def knn_classifier(embeddings_train, labels_train, embeddings_test, labels_test, k=5):\n",
    "    # Convert to CPU and numpy for sklearn\n",
    "    embeddings_train_np = embeddings_train.cpu().numpy()\n",
    "    labels_train_np = labels_train.cpu().numpy()\n",
    "    embeddings_test_np = embeddings_test.cpu().numpy()\n",
    "    labels_test_np = labels_test.cpu().numpy()\n",
    "\n",
    "    # Initialize the KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "    # Train the KNN classifier\n",
    "    knn.fit(embeddings_train_np, labels_train_np)\n",
    "    \n",
    "    # Predict on the test embeddings\n",
    "    predictions = knn.predict(embeddings_test_np)\n",
    "    \n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(labels_test_np, predictions)\n",
    "    print(f\"KNN Accuracy: {accuracy * 100:.2f}%\")\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    embeddings_train, labels_train = [], []\n",
    "    embeddings_test, labels_test = [], []\n",
    "\n",
    "    # Collect embeddings and labels for train and test sets\n",
    "    for batch in train_loader:\n",
    "        batch = batch.to(device)\n",
    "        inputs = (batch.weights, batch.biases)\n",
    "        labels = batch.label\n",
    "        \n",
    "        # Get embeddings as a tuple of tuples: ((w1, w2, w3), biases)\n",
    "        embeddings, _ = model(inputs)\n",
    "        weight_embeddings, biases_embeddings = embeddings\n",
    "        \n",
    "        # Unpack the weight embeddings tuple (w1, w2, w3)\n",
    "        w1, w2, w3 = weight_embeddings\n",
    "        \n",
    "        # Flatten each embedding (w1, w2, w3) and the biases\n",
    "        w1_flat = w1.view(w1.size(0), -1)\n",
    "        w2_flat = w2.view(w2.size(0), -1)\n",
    "        w3_flat = w3.view(w3.size(0), -1)\n",
    "        \n",
    "        # Unpack the weight embeddings tuple (w1, w2, w3)\n",
    "        b1, b2, b3 = biases_embeddings\n",
    "        \n",
    "        # Flatten each embedding (w1, w2, w3) and the biases\n",
    "        b1_flat = b1.view(b1.size(0), -1)\n",
    "        b2_flat = b2.view(b2.size(0), -1)\n",
    "        b3_flat = b3.view(b3.size(0), -1)\n",
    "        \n",
    "        # Concatenate all flattened embeddings into a single vector per sample\n",
    "        flattened_embeddings = torch.cat([w1_flat, w2_flat, w3_flat, b1_flat, b2_flat, b3_flat], dim=1)\n",
    "        \n",
    "        embeddings_train.append(flattened_embeddings)\n",
    "        labels_train.append(labels)\n",
    "\n",
    "    for batch in test_loader:\n",
    "        batch = batch.to(device)\n",
    "        inputs = (batch.weights, batch.biases)\n",
    "        labels = batch.label\n",
    "        \n",
    "        # Get embeddings as a tuple of tuples: ((w1, w2, w3), biases)\n",
    "        embeddings, _ = model(inputs)\n",
    "        weight_embeddings, biases_embeddings = embeddings\n",
    "        \n",
    "        # Unpack the weight embeddings tuple (w1, w2, w3)\n",
    "        w1, w2, w3 = weight_embeddings\n",
    "        \n",
    "        # Flatten each embedding (w1, w2, w3) and the biases\n",
    "        w1_flat = w1.view(w1.size(0), -1)\n",
    "        w2_flat = w2.view(w2.size(0), -1)\n",
    "        w3_flat = w3.view(w3.size(0), -1)\n",
    "        \n",
    "        # Unpack the weight embeddings tuple (w1, w2, w3)\n",
    "        b1, b2, b3 = biases_embeddings\n",
    "        \n",
    "        # Flatten each embedding (w1, w2, w3) and the biases\n",
    "        b1_flat = b1.view(b1.size(0), -1)\n",
    "        b2_flat = b2.view(b2.size(0), -1)\n",
    "        b3_flat = b3.view(b3.size(0), -1)\n",
    "        \n",
    "        # Concatenate all flattened embeddings into a single vector per sample\n",
    "        flattened_embeddings = torch.cat([w1_flat, w2_flat, w3_flat, b1_flat, b2_flat, b3_flat], dim=1)\n",
    "        \n",
    "        embeddings_test.append(flattened_embeddings)\n",
    "        labels_test.append(labels)\n",
    "\n",
    "    # Concatenate all the batches together\n",
    "    embeddings_train = torch.cat(embeddings_train, dim=0)\n",
    "    labels_train = torch.cat(labels_train, dim=0)\n",
    "    embeddings_test = torch.cat(embeddings_test, dim=0)\n",
    "    labels_test = torch.cat(labels_test, dim=0)\n",
    "\n",
    "    # Call the KNN classifier\n",
    "    knn_classifier(embeddings_train, labels_train, embeddings_test, labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc7ee9a-c299-45c8-b800-d54e3c6f329f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.models import DWSModelForClassification\n",
    "\n",
    "\n",
    "classfication_model = DWSModelForClassification(\n",
    "    weight_shapes=weight_shapes,\n",
    "    bias_shapes=bias_shapes,\n",
    "    input_features=1,\n",
    "    hidden_dim=32,\n",
    "    n_hidden=4,\n",
    "    bn=True,\n",
    ").to(device)\n",
    "\n",
    "classfication_model.load_state_dict(torch.load('Outputs/model_dws_classification.pth'))\n",
    "epochs = 25 \n",
    "@torch.no_grad()\n",
    "def evaluate(classfication_model, loader):\n",
    "    classfication_model.eval()\n",
    "    loss = 0.0\n",
    "    correct = 0.0\n",
    "    total = 0.0\n",
    "    predicted, gt = [], []\n",
    "    for batch in loader:\n",
    "        batch = batch.to(device)\n",
    "        inputs = (batch.weights, batch.biases)\n",
    "        out = classfication_model(model(inputs))\n",
    "        loss += F.cross_entropy(out, batch.label, reduction=\"sum\")\n",
    "        total += len(batch.label)\n",
    "        pred = out.argmax(1)\n",
    "        correct += pred.eq(batch.label).sum()\n",
    "        predicted.extend(pred.cpu().numpy().tolist())\n",
    "        gt.extend(batch.label.cpu().numpy().tolist())\n",
    "\n",
    "    classfication_model.train()\n",
    "    avg_loss = loss / total\n",
    "    avg_acc = correct / total\n",
    "\n",
    "    return dict(avg_loss=avg_loss, avg_acc=avg_acc, predicted=predicted, gt=gt)\n",
    "\n",
    "# optimizer = torch.optim.AdamW(params=classfication_model.parameters(), lr=1e-3, amsgrad=True, weight_decay=5e-4)\n",
    "\n",
    "# epoch_iter = trange(epochs)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# for epoch in epoch_iter:\n",
    "#     for i, batch in enumerate(train_loader):\n",
    "#         classfication_model.train()\n",
    "#         optimizer.zero_grad()\n",
    "\n",
    "#         batch = batch.to(device)\n",
    "#         inputs = (batch.weights, batch.biases)\n",
    "#         out = classfication_model(model(inputs))\n",
    "\n",
    "#         loss = criterion(out, batch.label)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "\n",
    "#         epoch_iter.set_description(\n",
    "#             f\"[{epoch} {i+1}], train loss: {loss.item():.3f}\"\n",
    "#         )\n",
    "        \n",
    "#     model_path = f\"Outputs/model_dws_classification_with_autoencoder.pth\"\n",
    "#     torch.save(classfication_model.state_dict(), model_path)\n",
    "#     test_loss_dict = evaluate(classfication_model, test_loader)\n",
    "#     test_acc = test_loss_dict['avg_acc'].item()\n",
    "#     print(\"accuracy for DWS Model for classification\", test_acc)\n",
    "    \n",
    "test_loss_dict = evaluate(classfication_model, test_loader)\n",
    "test_acc = test_loss_dict['avg_acc'].item()\n",
    "print(\"accuracy for new Autoencoder\", test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee55dee-165a-4b06-96a1-21a461b5addc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
