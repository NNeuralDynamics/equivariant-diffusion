{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c8a4c62c-dd84-4529-b51d-fe4d10e2783c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from argparse import ArgumentParser\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "# import wandb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange\n",
    "\n",
    "from experiments.data import INRDataset\n",
    "from experiments.utils import (\n",
    "    common_parser,\n",
    "    count_parameters,\n",
    "    get_device,\n",
    "    set_logger,\n",
    "    set_seed,\n",
    "    str2bool,\n",
    ")\n",
    "from nn.models import DWSModelForClassification, MLPModelForClassification\n",
    "\n",
    "from experiments.mnist.generate_data_splits import generate_splits\n",
    "from experiments.mnist.compute_statistics import compute_stats\n",
    "\n",
    "set_logger()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "748aa66c-d884-4e12-9b60-08963b725b64",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-31fb8d46adc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# The ID of the current GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# The name of the specified GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# The amount of GPUs that are accessible\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36mcurrent_device\u001b[0;34m()\u001b[0m\n\u001b[1;32m    876\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    877\u001b[0m     \u001b[0;34mr\"\"\"Return the index of a currently selected device.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 878\u001b[0;31m     \u001b[0m_lazy_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    879\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_getDevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    880\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/torch/cuda/__init__.py\u001b[0m in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menviron\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"CUDA_MODULE_LOADING\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"LAZY\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cuda_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         \u001b[0;31m# Some of the queued calls may reentrantly call _lazy_init();\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m         \u001b[0;31m# we need to just return without initializing in that case.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver."
     ]
    }
   ],
   "source": [
    "print(torch.cuda.current_device())  # The ID of the current GPU\n",
    "print(torch.cuda.get_device_name(0))  # The name of the specified GPU\n",
    "print(torch.cuda.device_count())  # The amount of GPUs that are accessible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae804791-6a1b-44ea-8613-320eb4b3c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0af17711-6813-44bc-9255-fe3227516f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gupta.saumy/.local/lib/python3.8/site-packages/torch/cuda/__init__.py:128: UserWarning: CUDA initialization: The NVIDIA driver on your system is too old (found version 11040). Please update your GPU driver by downloading and installing a new version from the URL: http://www.nvidia.com/Download/index.aspx Alternatively, go to: https://pytorch.org to install a PyTorch version that has been compiled with your version of the CUDA driver. (Triggered internally at ../c10/cuda/CUDAFunctions.cpp:108.)\n",
      "  return torch._C._cuda_getDeviceCount() > 0\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d648dfe5-e217-4c78-89dc-8a89b7e6867a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/work/talisman/sgupta/DWSNets/equivariant-diffusion\n"
     ]
    }
   ],
   "source": [
    "#Loading inr data we created while mnist training\n",
    "import os\n",
    "current_working_directory = os.getcwd()\n",
    "print(current_working_directory)\n",
    "path = current_working_directory + \"/notebooks/dataset/mnist_splits.json\"\n",
    "statistics_path = current_working_directory + \"/notebooks/dataset/statistics.pth\"\n",
    "normalize = True\n",
    "augmentation = True\n",
    "\n",
    "batch_size = 32\n",
    "num_workers = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c4cd5a5-40c4-4714-bdce-67c6cf64570d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:80: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.stats = torch.load(statistics_path, map_location=\"cpu\")\n",
      "2024-08-01 17:31:32,808 - root - INFO - train size 55000, val size 5000, test size 10000\n"
     ]
    }
   ],
   "source": [
    "train_set = INRDataset(\n",
    "        path=path,\n",
    "        split=\"train\",\n",
    "        normalize=normalize,\n",
    "        augmentation=augmentation,\n",
    "        statistics_path=statistics_path,\n",
    "    )\n",
    "\n",
    "val_set = INRDataset(\n",
    "    path=path,\n",
    "    split=\"val\",\n",
    "    normalize=normalize,\n",
    "    statistics_path=statistics_path,\n",
    ")\n",
    "\n",
    "test_set = INRDataset(\n",
    "    path=path,\n",
    "    split=\"test\",\n",
    "    normalize=normalize,\n",
    "    statistics_path=statistics_path,\n",
    ")\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "        dataset=train_set,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    dataset=val_set,\n",
    "    batch_size=batch_size,\n",
    "    num_workers=num_workers,\n",
    "    shuffle=False,\n",
    ")\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    dataset=test_set,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "logging.info(\n",
    "    f\"train size {len(train_set)}, \"\n",
    "    f\"val size {len(val_set)}, \"\n",
    "    f\"test size {len(test_set)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3eab7efc-56d3-4be4-b128-9230e5f6c87a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Latent_AE_cnn(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            in_dim,\n",
    "            time_step=1000,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # self.enc1 = nn.Sequential(nn.Conv1d(1, 10, 3, stride=1),nn.LeakyReLU(),nn.Conv1d(1, 10, 3, stride=1),)\n",
    "        self.in_dim = in_dim\n",
    "        self.fold_rate = 5\n",
    "        self.kernal_size = 5\n",
    "        self.channel_list = [4, 4, 4, 4]\n",
    "        self.channel_list_dec = [8, 256, 256, 4]\n",
    "        print(self.fold_rate)\n",
    "        print(self.kernal_size)\n",
    "        print(self.channel_list)\n",
    "        print(self.channel_list_dec)\n",
    "        self.real_input_dim = (\n",
    "                int(in_dim / self.fold_rate ** 4 + 1) * self.fold_rate ** 4\n",
    "        )\n",
    "\n",
    "        self.enc1 = nn.Sequential(\n",
    "            nn.InstanceNorm1d(self.real_input_dim),\n",
    "            nn.Conv1d(1, self.channel_list[0], self.kernal_size, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim),\n",
    "            nn.Conv1d(self.channel_list[0], self.channel_list[0], self.kernal_size, stride=self.fold_rate, padding=0),\n",
    "            # nn.MaxPool1d(2),\n",
    "        )\n",
    "        self.enc2 = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate),\n",
    "            nn.Conv1d(self.channel_list[0], self.channel_list[0], self.kernal_size, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate),\n",
    "            nn.Conv1d(self.channel_list[0], self.channel_list[1], self.kernal_size, stride=self.fold_rate, padding=0),\n",
    "            # nn.MaxPool1d(2),\n",
    "        )\n",
    "        self.enc3 = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate ** 2),\n",
    "            nn.Conv1d(self.channel_list[1], self.channel_list[1], self.kernal_size, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate ** 2),\n",
    "            nn.Conv1d(self.channel_list[1], self.channel_list[2], self.kernal_size, stride=self.fold_rate, padding=0),\n",
    "            # nn.MaxPool1d(2),\n",
    "        )\n",
    "        self.enc4 = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate ** 3),\n",
    "            nn.Conv1d(self.channel_list[2], self.channel_list[2], self.kernal_size, stride=1, padding=1),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate ** 3),\n",
    "            nn.Conv1d(self.channel_list[2], self.channel_list[3], self.kernal_size, stride=self.fold_rate, padding=0),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.dec1 = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate ** 4),\n",
    "            nn.ConvTranspose1d(\n",
    "                self.channel_list_dec[3], self.channel_list_dec[3], self.kernal_size, stride=self.fold_rate, padding=0\n",
    "            ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate ** 4),\n",
    "            nn.Conv1d(self.channel_list_dec[3], self.channel_list_dec[2], self.kernal_size, stride=1,\n",
    "                      padding=self.fold_rate - 1),\n",
    "        )\n",
    "        self.dec2 = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate ** 3),\n",
    "            nn.ConvTranspose1d(\n",
    "                self.channel_list_dec[2], self.channel_list_dec[2], self.kernal_size, stride=self.fold_rate, padding=0\n",
    "            ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate ** 3),\n",
    "            nn.Conv1d(self.channel_list_dec[2], self.channel_list_dec[1], self.kernal_size, stride=1,\n",
    "                      padding=self.fold_rate - 1),\n",
    "        )\n",
    "        self.dec3 = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate ** 2),\n",
    "            nn.ConvTranspose1d(\n",
    "                self.channel_list_dec[1], self.channel_list_dec[1], self.kernal_size, stride=self.fold_rate, padding=0\n",
    "            ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate ** 2),\n",
    "            nn.Conv1d(self.channel_list_dec[1], self.channel_list_dec[0], self.kernal_size, stride=1,\n",
    "                      padding=self.fold_rate - 1),\n",
    "        )\n",
    "        self.dec4 = nn.Sequential(\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate),\n",
    "            nn.ConvTranspose1d(\n",
    "                self.channel_list_dec[0], self.channel_list_dec[0], self.kernal_size, stride=self.fold_rate, padding=0\n",
    "            ),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.InstanceNorm1d(self.real_input_dim // self.fold_rate),\n",
    "            nn.Conv1d(self.channel_list_dec[0], 1, self.kernal_size, stride=1, padding=self.fold_rate),\n",
    "        )\n",
    "\n",
    "        # self.time_encode = nn.Embedding(time_step, self.real_input_dim)\n",
    "\n",
    "    def forward(self, input):\n",
    "        input_shape = input.shape\n",
    "        if len(input.size()) == 2:\n",
    "            input = input.view(input.size(0), 1, -1)\n",
    "\n",
    "        input = torch.cat(\n",
    "            [\n",
    "                input,\n",
    "                torch.zeros(input.shape[0], 1, (self.real_input_dim - self.in_dim)).to(\n",
    "                    input.device\n",
    "                ),\n",
    "            ],\n",
    "            dim=2,\n",
    "        )\n",
    "        emb_enc1 = self.enc1(input)\n",
    "        emb_enc2 = self.enc2(emb_enc1)\n",
    "        emb_enc3 = self.enc3(emb_enc2)\n",
    "        emb_enc4 = self.enc4(emb_enc3)\n",
    "\n",
    "        emb_enc4 = emb_enc4 + torch.randn_like(emb_enc4) * 0.1\n",
    "\n",
    "        emb_dec1 = self.dec1(emb_enc4)\n",
    "        emb_dec2 = self.dec2(emb_dec1)\n",
    "        emb_dec3 = self.dec3(emb_dec2)\n",
    "        emb_dec4 = self.dec4(emb_dec3)[:, :, :input_shape[-1]]\n",
    "\n",
    "        return emb_dec4.reshape(input_shape)\n",
    "\n",
    "    def Enc(self, input):\n",
    "        if len(input.size()) == 2:\n",
    "            input = input.view(input.size(0), 1, -1)\n",
    "\n",
    "        input = torch.cat(\n",
    "            [\n",
    "                input,\n",
    "                torch.zeros(input.shape[0], 1, (self.real_input_dim - self.in_dim)).to(input.device),\n",
    "            ],\n",
    "            dim=2,\n",
    "        )\n",
    "        emb_enc1 = self.enc1(input)\n",
    "        emb_enc2 = self.enc2(emb_enc1)\n",
    "        emb_enc3 = self.enc3(emb_enc2)\n",
    "        emb_enc4 = self.enc4(emb_enc3)\n",
    "\n",
    "        return emb_enc4\n",
    "\n",
    "    def Dec(self, emb_enc4):\n",
    "        emb_dec1 = self.dec1(emb_enc4)\n",
    "        emb_dec2 = self.dec2(emb_dec1)\n",
    "        emb_dec3 = self.dec3(emb_dec2)\n",
    "        emb_dec4 = self.dec4(emb_dec3)[:, :, :self.in_dim]\n",
    "\n",
    "        return emb_dec4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "a809cafe-c54e-4330-865b-cf95eb923e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_input(batch):\n",
    "    weights, biases = batch.weights, batch.biases\n",
    "\n",
    "    # Flatten weights and biases\n",
    "    weights_flat = [torch.flatten(w) for w in weights]\n",
    "    biases_flat = [torch.flatten(b) for b in biases]\n",
    "\n",
    "    # Concatenate weights and biases\n",
    "    combined_flat_input = [torch.cat((w, b)) for w, b in zip(weights_flat, biases_flat)]\n",
    "\n",
    "    # Determine the maximum length of tensors in the batch\n",
    "    max_length = max(tensor.size(0) for tensor in combined_flat_input)\n",
    "\n",
    "    # Pad tensors to the maximum length\n",
    "    padded_tensors = []\n",
    "    for tensor in combined_flat_input:\n",
    "        padding_length = max_length - tensor.size(0)\n",
    "        if padding_length > 0:\n",
    "            padded_tensor = torch.cat((tensor, torch.zeros(padding_length)))\n",
    "        else:\n",
    "            padded_tensor = tensor\n",
    "        padded_tensors.append(padded_tensor)\n",
    "\n",
    "    # Stack padded tensors into a single tensor\n",
    "    padded_tensor_stack = torch.stack(padded_tensors)\n",
    "\n",
    "    # Maintain batch size\n",
    "    batch_size = batch.weights[0].size(0)  # Assuming all weights have the same batch size\n",
    "    padded_tensor_stack = padded_tensor_stack.view(batch_size, -1)\n",
    "    return padded_tensor_stack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2cd170ce-8e27-4de3-a5a5-ebcdbabf8e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "def train_model(model):\n",
    "    learning_rate = 1e-3\n",
    "    num_epochs = 1000\n",
    "    criterion =  nn.MSELoss()\n",
    "    epoch_iter = trange(num_epochs)\n",
    "    epoch_loss = -1\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    scheduler = StepLR(optimizer, step_size=250, gamma=0.1)\n",
    "\n",
    "    for epoch in epoch_iter:\n",
    "        total_loss = 0\n",
    "        counter = 0\n",
    "        for i, batch in enumerate(train_loader):\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            batch = batch.to(device)\n",
    "            data = reshape_input(batch)\n",
    "            out = model(data)\n",
    "            loss = criterion(out, data)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_iter.set_description(\n",
    "                f\"[{epoch} {i+1}], train loss: {loss.item():.3f}, epoch loss: {epoch_loss:.3f}\"\n",
    "            )\n",
    "            \n",
    "            total_loss = total_loss + loss.item()\n",
    "            counter +=1\n",
    "        epoch_loss = total_loss/counter\n",
    "        scheduler.step()\n",
    "        if (epoch+1)%25 == 0:\n",
    "            torch.save(model.state_dict(), f\"Outputs/model4_epoch{epoch}_loss{epoch_loss}.pth\")   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "50bd1b1d-5fd3-4c2f-ac01-14b26fd4f115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "\n",
    "# # Example DataLoader loop\n",
    "# for i, batch in enumerate(train_loader):\n",
    "#     batch = batch.to(device)\n",
    "\n",
    "#     weights, biases = batch.weights, batch.biases\n",
    "\n",
    "#     # Flatten weights and biases\n",
    "#     weights_flat = [torch.flatten(w) for w in weights]\n",
    "#     biases_flat = [torch.flatten(b) for b in biases]\n",
    "\n",
    "#     # Concatenate weights and biases\n",
    "#     combined_flat_input = [torch.cat((w, b)) for w, b in zip(weights_flat, biases_flat)]\n",
    "\n",
    "#     # Determine the maximum length of tensors in the batch\n",
    "#     max_length = max(tensor.size(0) for tensor in combined_flat_input)\n",
    "\n",
    "#     # Pad tensors to the maximum length\n",
    "#     padded_tensors = []\n",
    "#     for tensor in combined_flat_input:\n",
    "#         padding_length = max_length - tensor.size(0)\n",
    "#         if padding_length > 0:\n",
    "#             # Pad tensor with zeros\n",
    "#             padded_tensor = torch.cat((tensor, torch.zeros(padding_length)))\n",
    "#         else:\n",
    "#             padded_tensor = tensor\n",
    "#         padded_tensors.append(padded_tensor)\n",
    "\n",
    "#     # Stack padded tensors into a single tensor\n",
    "#     padded_tensor_stack = torch.stack(padded_tensors)\n",
    "\n",
    "#     # Maintain batch size\n",
    "#     batch_size = batch.weights[0].size(0)  # Assuming all weights have the same batch size\n",
    "#     padded_tensor_stack = padded_tensor_stack.view(batch_size, -1)\n",
    "\n",
    "#     # Print results\n",
    "#     for j, tensor in enumerate(padded_tensors):\n",
    "#         print(f\"Padded tensor {j}:\", tensor)\n",
    "#     print(\"Stacked padded tensor shape:\", padded_tensor_stack.shape)\n",
    "    \n",
    "#     # Break after first batch for demonstration\n",
    "#     break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1a5e4cc-b3e3-4276-85a9-8109c0e141fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "5\n",
      "[4, 4, 4, 4]\n",
      "[8, 256, 256, 4]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[0 1719], train loss: 0.379, epoch loss: -1.000:   0%|          | 1/1000 [04:30<74:56:36, 270.07s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[1 1719], train loss: 0.366, epoch loss: 0.387:   0%|          | 2/1000 [12:04<105:00:52, 378.81s/it]/work/talisman/sgupta/DWSNets/equivariant-diffusion/experiments/data.py:210: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(path, map_location=lambda storage, loc: storage)\n",
      "[2 1436], train loss: 0.364, epoch loss: 0.384:   0%|          | 2/1000 [17:56<105:00:52, 378.81s/it]"
     ]
    }
   ],
   "source": [
    "model = Latent_AE_cnn(\n",
    "   in_dim = 3168\n",
    ").to(device)\n",
    "train_model(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8",
   "language": "python",
   "name": "py3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
