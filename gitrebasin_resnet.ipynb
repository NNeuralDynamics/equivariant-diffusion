{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b282ada-4e64-4905-a1cd-fecdbdc76911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before matching accuracy: 74.13%\n",
      "After matching accuracy: 74.13%\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torchvision import transforms, datasets\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import copy\n",
    "from collections import defaultdict, namedtuple\n",
    "from typing import NamedTuple\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import logging\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "import torchvision\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "\n",
    "# Set up device and logging\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)s %(levelname)s: %(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n",
    "\n",
    "# --------------------------- RESNET MODEL DEFINITION --------------------------- #\n",
    "# Basic Residual Block\n",
    "class BasicBlock(nn.Module):\n",
    "    expansion = 1\n",
    "\n",
    "    def __init__(self, in_planes, planes, stride=1):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_planes, planes, 3, stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(planes)\n",
    "        self.conv2 = nn.Conv2d(planes, planes, 3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(planes)\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_planes != planes:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_planes, planes, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(planes)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "# ResNet for CIFAR-10\n",
    "class ResNet(nn.Module):\n",
    "    def __init__(self, block, num_blocks, num_classes=10):\n",
    "        super().__init__()\n",
    "        self.in_planes = 16\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.layer1 = self._make_layer(block, 16, num_blocks[0], stride=1)\n",
    "        self.layer2 = self._make_layer(block, 32, num_blocks[1], stride=2)\n",
    "        self.layer3 = self._make_layer(block, 64, num_blocks[2], stride=2)\n",
    "        self.linear = nn.Linear(64, num_classes)\n",
    "\n",
    "    def _make_layer(self, block, planes, num_blocks, stride):\n",
    "        strides = [stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for s in strides:\n",
    "            layers.append(block(self.in_planes, planes, s))\n",
    "            self.in_planes = planes * block.expansion\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))  # 32x32\n",
    "        out = self.layer1(out)  # 32x32\n",
    "        out = self.layer2(out)  # 16x16\n",
    "        out = self.layer3(out)  # 8x8\n",
    "        out = F.avg_pool2d(out, 8)  # Global avg pool\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out\n",
    "\n",
    "def ResNet20():\n",
    "    return ResNet(BasicBlock, [3,3,3])\n",
    "\n",
    "# --------------------------- WEIGHT MATCHING CODE --------------------------- #\n",
    "\n",
    "# PermutationSpec class for defining permutable dimensions\n",
    "class PermutationSpec(NamedTuple):\n",
    "    perm_to_axes: dict\n",
    "    axes_to_perm: dict\n",
    "\n",
    "def permutation_spec_from_axes_to_perm(axes_to_perm: dict) -> PermutationSpec:\n",
    "    perm_to_axes = defaultdict(list)\n",
    "    for wk, axis_perms in axes_to_perm.items():\n",
    "        for axis, perm in enumerate(axis_perms):\n",
    "            if perm is not None:\n",
    "                perm_to_axes[perm].append((wk, axis))\n",
    "    return PermutationSpec(perm_to_axes=dict(perm_to_axes), axes_to_perm=axes_to_perm)\n",
    "\n",
    "def norm(name, p):\n",
    "    return {\n",
    "        f\"{name}.weight\": (p,),  # gamma\n",
    "        f\"{name}.bias\": (p,),    # beta\n",
    "        f\"{name}.running_mean\": (p,),  # running mean buffer\n",
    "        f\"{name}.running_var\": (p,),   # running var buffer\n",
    "    }\n",
    "\n",
    "def resnet_permutation_spec() -> PermutationSpec:\n",
    "    conv = lambda name, p_in, p_out: {f\"{name}.weight\": (p_out, p_in, None, None)}\n",
    "\n",
    "    norm = lambda name, p: {\n",
    "        f\"{name}.weight\": (p,),\n",
    "        f\"{name}.bias\": (p,),\n",
    "        f\"{name}.running_mean\": (p,),\n",
    "        f\"{name}.running_var\": (p,),\n",
    "    }\n",
    "\n",
    "    dense = lambda name, p_in, p_out: {\n",
    "        f\"{name}.weight\": (p_out, p_in),\n",
    "        f\"{name}.bias\": (p_out,)\n",
    "    }\n",
    "\n",
    "    easyblock = lambda name, p: {\n",
    "        **conv(f\"{name}.conv1\", p, f\"P_{name}_inner\"),\n",
    "        **norm(f\"{name}.bn1\", f\"P_{name}_inner\"),\n",
    "        **conv(f\"{name}.conv2\", f\"P_{name}_inner\", p),\n",
    "        **norm(f\"{name}.bn2\", p),\n",
    "    }\n",
    "\n",
    "    shortcutblock = lambda name, p_in, p_out: {\n",
    "        **conv(f\"{name}.conv1\", p_in, f\"P_{name}_inner\"),\n",
    "        **norm(f\"{name}.bn1\", f\"P_{name}_inner\"),\n",
    "        **conv(f\"{name}.conv2\", f\"P_{name}_inner\", p_out),\n",
    "        **norm(f\"{name}.bn2\", p_out),\n",
    "        **conv(f\"{name}.shortcut.0\", p_in, p_out),\n",
    "        **norm(f\"{name}.shortcut.1\", p_out),\n",
    "    }\n",
    "\n",
    "    return permutation_spec_from_axes_to_perm({\n",
    "        **conv(\"conv1\", None, \"P_bg0\"),\n",
    "        **norm(\"bn1\", \"P_bg0\"),\n",
    "\n",
    "        **easyblock(\"layer1.0\", \"P_bg0\"),\n",
    "        **easyblock(\"layer1.1\", \"P_bg0\"),\n",
    "        **easyblock(\"layer1.2\", \"P_bg0\"),\n",
    "\n",
    "        **shortcutblock(\"layer2.0\", \"P_bg0\", \"P_bg1\"),\n",
    "        **easyblock(\"layer2.1\", \"P_bg1\"),\n",
    "        **easyblock(\"layer2.2\", \"P_bg1\"),\n",
    "\n",
    "        **shortcutblock(\"layer3.0\", \"P_bg1\", \"P_bg2\"),\n",
    "        **easyblock(\"layer3.1\", \"P_bg2\"),\n",
    "        **easyblock(\"layer3.2\", \"P_bg2\"),\n",
    "\n",
    "        **dense(\"linear\", \"P_bg2\", None),\n",
    "    })\n",
    "\n",
    "def get_permuted_param(ps: PermutationSpec, perm, k: str, params, except_axis=None):\n",
    "  \"\"\"Get parameter `k` from `params`, with the permutations applied.\"\"\"\n",
    "  w = params[k]\n",
    "  for axis, p in enumerate(ps.axes_to_perm[k]):\n",
    "    # Skip the axis we're trying to permute.\n",
    "    if axis == except_axis:\n",
    "      continue\n",
    "\n",
    "    # None indicates that there is no permutation relevant to that axis.\n",
    "    if p is not None:\n",
    "      w = jnp.take(w, perm[p], axis=axis)\n",
    "\n",
    "  return w\n",
    "\n",
    "def apply_permutation(ps: PermutationSpec, perm, params):\n",
    "  \"\"\"Apply a `perm` to `params`.\"\"\"\n",
    "  return {k: get_permuted_param(ps, perm, k, params) for k in params.keys()}\n",
    "\n",
    "def rngmix(rng, i):\n",
    "    \"\"\"Mix a base RNG with an integer to generate a new RNG.\"\"\"\n",
    "    return random.fold_in(rng, i)\n",
    "\n",
    "\n",
    "def weight_matching(rng,\n",
    "                    ps: PermutationSpec,\n",
    "                    params_a,\n",
    "                    params_b,\n",
    "                    max_iter=100,\n",
    "                    init_perm=None,\n",
    "                    silent=True):\n",
    "    \"\"\"Find a permutation of `params_b` to make them match `params_a`.\"\"\"\n",
    "    perm_sizes = {p: params_a[axes[0][0]].shape[axes[0][1]] for p, axes in ps.perm_to_axes.items()}\n",
    "    \n",
    "    perm = {p: jnp.arange(n) for p, n in perm_sizes.items()} if init_perm is None else init_perm\n",
    "    perm_names = list(perm.keys())\n",
    "    \n",
    "    for iteration in range(max_iter):\n",
    "        progress = False\n",
    "        for p_ix in random.permutation(rngmix(rng, iteration), len(perm_names)):\n",
    "          p = perm_names[p_ix]\n",
    "          n = perm_sizes[p]\n",
    "          A = jnp.zeros((n, n))\n",
    "          for wk, axis in ps.perm_to_axes[p]:\n",
    "            w_a = params_a[wk]\n",
    "            w_b = get_permuted_param(ps, perm, wk, params_b, except_axis=axis)\n",
    "            w_a = jnp.moveaxis(w_a, axis, 0).reshape((n, -1))\n",
    "            w_b = jnp.moveaxis(w_b, axis, 0).reshape((n, -1))\n",
    "            A += w_a @ w_b.T\n",
    "        \n",
    "          ri, ci = linear_sum_assignment(A, maximize=True)\n",
    "          assert (ri == jnp.arange(len(ri))).all()\n",
    "        \n",
    "          oldL = jnp.vdot(A, jnp.eye(n)[perm[p]])\n",
    "          newL = jnp.vdot(A, jnp.eye(n)[ci, :])\n",
    "          if not silent: print(f\"{iteration}/{p}: {newL - oldL}\")\n",
    "          progress = progress or newL > oldL + 1e-12\n",
    "        \n",
    "          perm[p] = jnp.array(ci)\n",
    "        \n",
    "        if not progress:\n",
    "          break\n",
    "        \n",
    "        return perm\n",
    "\n",
    "# --------------------------- WEIGHT MATCHING AND FLOW MATCHING PIPELINE --------------------------- #\n",
    "\n",
    "\n",
    "def get_test_loader(batch_size=128):\n",
    "    transform_test = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.4914, 0.4822, 0.4465),  # CIFAR-10 mean\n",
    "                             (0.2023, 0.1994, 0.2010))  # CIFAR-10 std\n",
    "    ])\n",
    "\n",
    "    test_set = torchvision.datasets.CIFAR10(\n",
    "        root='./data', train=False, download=True, transform=transform_test\n",
    "    )\n",
    "\n",
    "    test_loader = DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "    return test_loader\n",
    "\n",
    "\n",
    "def evaluate(model, test_loader, device='cuda' if torch.cuda.is_available() else 'cpu'):\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "    accuracy = 100.0 * correct / total\n",
    "    return accuracy\n",
    "\n",
    "from collections import OrderedDict\n",
    "import jax.numpy as jnp\n",
    "from jax import random\n",
    "\n",
    "def test_weight_matching(model_dir=\"imagenet_resnet_models\"):\n",
    "    \"\"\"Tests weight matching between two ResNet20 models trained separately.\"\"\"\n",
    "\n",
    "    # Define device and instantiate models\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    model_a = ResNet20().to(device)\n",
    "    model_b = ResNet20().to(device)\n",
    "\n",
    "    # Load pretrained weights into the PyTorch models first\n",
    "    ref_point = 0\n",
    "    perm_point = 100\n",
    "    ref_model_path = f\"{model_dir}/resnet_weights_{ref_point}.pt\"\n",
    "    perm_model_path = f\"{model_dir}/resnet_weights_{perm_point}.pt\"\n",
    "    model_a.load_state_dict(torch.load(ref_model_path, map_location=device))\n",
    "    model_b.load_state_dict(torch.load(perm_model_path, map_location=device))\n",
    "\n",
    "    # Get permutation spec\n",
    "    ps = resnet_permutation_spec()\n",
    "\n",
    "    # Extract relevant parameters and convert them to JAX arrays\n",
    "    params_a = {k: v.clone().detach() for k, v in model_a.state_dict().items() if k in ps.axes_to_perm}\n",
    "    params_b = {k: v.clone().detach() for k, v in model_b.state_dict().items() if k in ps.axes_to_perm}\n",
    "    params_a_jax = {k: jnp.array(v.cpu().numpy()) for k, v in params_a.items()}\n",
    "    params_b_jax = {k: jnp.array(v.cpu().numpy()) for k, v in params_b.items()}\n",
    "\n",
    "    # Evaluate before matching\n",
    "    test_loader = get_test_loader()\n",
    "    accuracy_before_matching = evaluate(model_b, test_loader)\n",
    "\n",
    "    # Perform weight matching (in JAX)\n",
    "    rng = random.PRNGKey(123)\n",
    "    perm = weight_matching(rng, ps, params_a_jax, params_b_jax)\n",
    "\n",
    "    # Apply permutation to params_b (in JAX)\n",
    "    permuted_params_b = apply_permutation(ps, perm, params_b_jax)\n",
    "\n",
    "    # Convert permuted parameters back to PyTorch tensors\n",
    "    permuted_params_b_torch = {k: torch.tensor(np.array(v)) for k, v in permuted_params_b.items()}\n",
    "\n",
    "    # Update model_b with permuted parameters\n",
    "    state_dict_b = model_b.state_dict()\n",
    "    for k in permuted_params_b_torch:\n",
    "        state_dict_b[k] = permuted_params_b_torch[k]\n",
    "    model_b.load_state_dict(state_dict_b)\n",
    "\n",
    "    # Evaluate after matching\n",
    "    accuracy_after_matching = evaluate(model_b, test_loader)\n",
    "\n",
    "    # Print results\n",
    "    print(f\"Before matching accuracy: {accuracy_before_matching:.2f}%\")\n",
    "    print(f\"After matching accuracy: {accuracy_after_matching:.2f}%\")\n",
    "    \n",
    "test_weight_matching()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
