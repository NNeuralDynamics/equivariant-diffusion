{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e745750-df87-4359-be96-0ea8d8a5fb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/ege-erdogan/weightflow/tree/master\n",
    "# !pip install git+https://github.com/ege-erdogan/weightflow.git\n",
    "# !git clone https://github.com/ege-erdogan/weightflow.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e90da6b-4fc7-41cb-9c55-025a51081c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# update scipy, \n",
    "# pip install einops\n",
    "# !pip install rebasin\n",
    "# !pip install graphviz\n",
    "# !pip install -r ./weightflow/requirements.txt\n",
    "\n",
    "# I can feel the worms in my head :(\n",
    "# Anyways, this notebook contains Conditional multiclass flow matching for MNIST and Fashion MNIST MLPs\n",
    "# * Git rebasin\n",
    "# * Flow matching and generation testing\n",
    "# * Hybrid embedding generation\n",
    "# * Populating larger hidden dims from generated weight space dists (sorta works?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7575fa8d-956b-4ce4-8cc1-a205027f5049",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./weightflow')  # e.g., './repo_name'\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from typing import NamedTuple\n",
    "from scipy.optimize import linear_sum_assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "213b4c7a-45ed-4c2e-a429-d281a50b5ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nn.relational_transformer import RelationalTransformer\n",
    "from nn.graph_constructor import GraphConstructor\n",
    "from flow.flow_matching import CFM\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "import logging\n",
    "from utils.data import sample_gaussian_wsos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a202e7a-6fad-403f-b0da-a5f54cec3ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "logging.basicConfig(stream=sys.stdout, format='%(asctime)s %(levelname)s: %(message)s', level=logging.INFO, datefmt='%I:%M:%S')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aecf99f6-9473-4929-bd0d-63eef5b5947c",
   "metadata": {},
   "source": [
    "# Ok, imports done. Now rebasin stuff. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbed8150-9d31-4b73-9ca3-e6640e2f1c3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PermutationSpec class similar to the JAX version but using PyTorch\n",
    "class PermutationSpec(NamedTuple):\n",
    "    perm_to_axes: dict\n",
    "    axes_to_perm: dict\n",
    "\n",
    "def permutation_spec_from_axes_to_perm(axes_to_perm: dict) -> PermutationSpec:\n",
    "    perm_to_axes = defaultdict(list)\n",
    "    for wk, axis_perms in axes_to_perm.items():\n",
    "        for axis, perm in enumerate(axis_perms):\n",
    "            if perm is not None:\n",
    "                perm_to_axes[perm].append((wk, axis))\n",
    "    return PermutationSpec(perm_to_axes=dict(perm_to_axes), axes_to_perm=axes_to_perm)\n",
    "\n",
    "def mlp_permutation_spec_mlp() -> PermutationSpec:\n",
    "    \"\"\"Define permutation spec for MLP architecture\"\"\"\n",
    "    return permutation_spec_from_axes_to_perm({\n",
    "        \"fc1.weight\": (None, \"P_0\"),       # Input (None) to fc1 output (P_0)\n",
    "        \"fc1.bias\": (\"P_0\",),              # Bias for fc1 output (P_0)\n",
    "        \"fc2.weight\": (\"P_0\", \"P_1\"),      # fc1 output (P_0) to fc2 output (P_1)\n",
    "        \"fc2.bias\": (\"P_1\",),              # Bias for fc2 output (P_1)\n",
    "        \"fc3.weight\": (\"P_1\", None),       # fc2 output (P_1) to fc3 output (None)\n",
    "        \"fc3.bias\": (None,),               # Bias for fc3 output (None)\n",
    "    })\n",
    "\n",
    "def get_permuted_param(ps: PermutationSpec, perm, k: str, params, except_axis=None):\n",
    "    \"\"\"Get parameter k from params, with permutations applied.\"\"\"\n",
    "    w = params[k]\n",
    "    for axis, p in enumerate(ps.axes_to_perm[k]):\n",
    "        # Skip the axis we're trying to permute\n",
    "        if axis == except_axis:\n",
    "            continue\n",
    "\n",
    "        # None indicates no permutation for that axis\n",
    "        if p is not None:\n",
    "            w = torch.index_select(w, axis, torch.tensor(perm[p], device=w.device))\n",
    "\n",
    "    return w\n",
    "\n",
    "def apply_permutation(ps: PermutationSpec, perm, params):\n",
    "    \"\"\"Apply permutation to params\"\"\"\n",
    "    return {k: get_permuted_param(ps, perm, k, params) for k in params.keys()}\n",
    "\n",
    "def weight_matching(ps: PermutationSpec, params_a, params_b, max_iter=100, init_perm=None, silent=True, device=None):\n",
    "    \"\"\"Find permutation of params_b to make them match params_a.\"\"\"\n",
    "    if device is None:\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Move all tensors to the correct device\n",
    "    params_a = {k: v.to(device) for k, v in params_a.items()}\n",
    "    params_b = {k: v.to(device) for k, v in params_b.items()}\n",
    "\n",
    "    # Get permutation sizes from the first parameter with each permutation\n",
    "    perm_sizes = {p: params_a[axes[0][0]].shape[axes[0][1]] \n",
    "                  for p, axes in ps.perm_to_axes.items()}\n",
    "    \n",
    "    # Initialize permutations to identity if none provided\n",
    "    if init_perm is None:\n",
    "        perm = {p: torch.arange(n, device=device) for p, n in perm_sizes.items()}\n",
    "    else:\n",
    "        perm = {p: v.to(device) for p, v in init_perm.items()}\n",
    "        \n",
    "    perm_names = list(perm.keys())\n",
    "    \n",
    "    # Use a random number generator with a fixed seed for reproducibility\n",
    "    rng = np.random.RandomState(42)\n",
    "\n",
    "    for iteration in range(max_iter):\n",
    "        progress = False\n",
    "        \n",
    "        # Shuffle the order of permutations to update\n",
    "        for p_ix in rng.permutation(len(perm_names)):\n",
    "            p = perm_names[p_ix]\n",
    "            n = perm_sizes[p]\n",
    "            \n",
    "            # Initialize cost matrix\n",
    "            A = torch.zeros((n, n), device=device)\n",
    "            \n",
    "            # Fill in cost matrix based on all parameters affected by this permutation\n",
    "            for wk, axis in ps.perm_to_axes[p]:\n",
    "                w_a = params_a[wk]\n",
    "                w_b = get_permuted_param(ps, perm, wk, params_b, except_axis=axis)\n",
    "\n",
    "                w_a = w_a.moveaxis(axis, 0).reshape((n, -1))\n",
    "                w_b = w_b.moveaxis(axis, 0).reshape((n, -1))\n",
    "\n",
    "                A += w_a @ w_b.T\n",
    "\n",
    "            # Solve the linear assignment problem\n",
    "            ri, ci = linear_sum_assignment(A.detach().cpu().numpy(), maximize=True)\n",
    "            assert (ri == np.arange(len(ri))).all()\n",
    "\n",
    "            # Calculate improvement\n",
    "            eye_old = torch.eye(n, device=device)[perm[p]]\n",
    "            eye_new = torch.eye(n, device=device)[ci]\n",
    "\n",
    "            oldL = torch.tensordot(A, eye_old, dims=([0, 1], [0, 1]))\n",
    "            newL = torch.tensordot(A, eye_new, dims=([0, 1], [0, 1]))\n",
    "\n",
    "            if not silent and newL > oldL + 1e-12:\n",
    "                logging.info(f\"{iteration}/{p}: {newL.item() - oldL.item()}\")\n",
    "\n",
    "            progress = progress or newL > oldL + 1e-12\n",
    "\n",
    "            perm[p] = torch.tensor(ci, device=device)\n",
    "\n",
    "        if not progress:\n",
    "            break\n",
    "\n",
    "    return perm\n",
    "\n",
    "\n",
    "def update_model_weights(model, aligned_params):\n",
    "    \"\"\"Update model weights with aligned parameters\"\"\"\n",
    "    # Convert numpy arrays to torch tensors if needed\n",
    "    model.fc1.weight.data = aligned_params[\"fc1.weight\"].T\n",
    "    model.fc1.bias.data = aligned_params[\"fc1.bias\"]\n",
    "    model.fc2.weight.data = aligned_params[\"fc2.weight\"].T\n",
    "    model.fc2.bias.data = aligned_params[\"fc2.bias\"]\n",
    "    model.fc3.weight.data = aligned_params[\"fc3.weight\"].T\n",
    "    model.fc3.bias.data = aligned_params[\"fc3.bias\"]\n",
    "    \n",
    "def load_model_weights(model, model_path):\n",
    "    \"\"\"Load model weights from file\"\"\"\n",
    "    weights, biases = torch.load(model_path, map_location=device)\n",
    "    model.fc1.weight.data = weights[0]\n",
    "    model.fc1.bias.data = biases[0]\n",
    "    model.fc2.weight.data = weights[1]\n",
    "    model.fc2.bias.data = biases[1]\n",
    "    model.fc3.weight.data = weights[2]\n",
    "    model.fc3.bias.data = biases[2]\n",
    "    return model.to(device)\n",
    "\n",
    "def get_permuted_models_data(ref_point=0, model_dir=\"models\", num_models=200, model_type = f'MNIST'):\n",
    "    \"\"\"Apply weight matching to align models with a reference model\"\"\"\n",
    "    # Create reference model\n",
    "    ref_model = MLP()  # Assumes MLP class is defined\n",
    "    ref_model_path = f\"{model_dir}/{model_type}_mixed_mlp_weights_{ref_point}.pt\"\n",
    "    ref_model = load_model_weights(ref_model, ref_model_path).to(device)\n",
    "    \n",
    "    ps = mlp_permutation_spec_mlp()\n",
    "    \n",
    "    # Convert reference model weights to dictionary format\n",
    "    params_a = {\n",
    "        \"fc1.weight\": ref_model.fc1.weight.T.to(device),\n",
    "        \"fc1.bias\": ref_model.fc1.bias.to(device),\n",
    "        \"fc2.weight\": ref_model.fc2.weight.T.to(device),\n",
    "        \"fc2.bias\": ref_model.fc2.bias.to(device),\n",
    "        \"fc3.weight\": ref_model.fc3.weight.T.to(device),\n",
    "        \"fc3.bias\": ref_model.fc3.bias.to(device),\n",
    "    }\n",
    "    \n",
    "    org_models = []\n",
    "    permuted_models = []\n",
    "\n",
    "    for i in range(0, num_models):\n",
    "        if i == ref_point:\n",
    "            continue\n",
    "            \n",
    "        model_path = f\"{model_dir}/{model_type}_mixed_mlp_weights_{i}.pt\"\n",
    "\n",
    "        model = MLP()  # Assumes MLP class is defined\n",
    "        model = load_model_weights(model, model_path).to(device)\n",
    "        org_models.append(model)\n",
    "        \n",
    "        # Convert model weights to dictionary format\n",
    "        params_b = {\n",
    "                \"fc1.weight\": model.fc1.weight.T.to(device),\n",
    "                \"fc1.bias\": model.fc1.bias.to(device),\n",
    "                \"fc2.weight\": model.fc2.weight.T.to(device),\n",
    "                \"fc2.bias\": model.fc2.bias.to(device),\n",
    "                \"fc3.weight\": model.fc3.weight.T.to(device),\n",
    "                \"fc3.bias\": model.fc3.bias.to(device),\n",
    "        }\n",
    "\n",
    "        # Find permutation to align with reference model\n",
    "        perm = weight_matching(ps, params_a, params_b)\n",
    "        \n",
    "        # Apply permutation to model_b\n",
    "        aligned_params_b = apply_permutation(ps, perm, params_b)\n",
    "        \n",
    "        # Create a new model with permuted weights\n",
    "        reconstructed_model = copy.deepcopy(model)\n",
    "        update_model_weights(reconstructed_model, aligned_params_b)\n",
    "        \n",
    "        permuted_models.append(reconstructed_model.to(device))\n",
    "\n",
    "            \n",
    "    return ref_model, org_models, permuted_models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6656ddf6-85a3-4a58-93f8-3762182946e9",
   "metadata": {},
   "source": [
    "# Not sure whats next but ok, \n",
    "* Review WSOs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1f26f9-2362-4a19-9bb3-fe7b75885872",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "import os\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5926b4-677c-4476-a546-863c5d20df31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define MNIST classifier MLP class for dataset\n",
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "    A fully connected 3 layer neural network for classification tasks where hidden layers have 32 neurons (default) and ReLU activations\n",
    "    input: torch.tensor( [batch_size, 196] )\n",
    "    output: torch.tensor( [batch_size, 10] )\n",
    "    For classifying inputs of 196 into 10 classes.\n",
    "    \"\"\"\n",
    "    def __init__(self, hidden_dim = 32, init_type='xavier', seed=None, type = 'MNIST'):\n",
    "        super(MLP, self).__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(196, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc3 = nn.Linear(hidden_dim, 10)\n",
    "        \n",
    "        if seed is not None:\n",
    "            torch.manual_seed(seed)  # Set a unique seed for reproducibility\n",
    "\n",
    "        self.init_weights(init_type)\n",
    "        self.type = type\n",
    "\n",
    "    def init_weights(self, init_type):\n",
    "        if init_type == 'xavier':\n",
    "            nn.init.xavier_uniform_(self.fc1.weight)\n",
    "            nn.init.xavier_uniform_(self.fc2.weight)\n",
    "            nn.init.xavier_uniform_(self.fc3.weight)\n",
    "        elif init_type == 'he':\n",
    "            nn.init.kaiming_uniform_(self.fc1.weight, nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc2.weight, nonlinearity='relu')\n",
    "            nn.init.kaiming_uniform_(self.fc3.weight, nonlinearity='relu')\n",
    "        else:\n",
    "            nn.init.normal_(self.fc1.weight)\n",
    "            nn.init.normal_(self.fc2.weight)\n",
    "            nn.init.normal_(self.fc3.weight)\n",
    "        \n",
    "        nn.init.zeros_(self.fc1.bias)\n",
    "        nn.init.zeros_(self.fc2.bias)\n",
    "        nn.init.zeros_(self.fc3.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 196)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = torch.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "def test_mlp(model, test_loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    model = model.to(device)\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            _, predicted = torch.max(output.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "    return 100 * correct / total\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "def zero_like_wso(wso):\n",
    "    zero_weights = tuple(torch.zeros_like(w) for w in wso.weights)\n",
    "    zero_biases = tuple(torch.zeros_like(b) for b in wso.biases)\n",
    "    return WeightSpaceObject(zero_weights, zero_biases)\n",
    "\n",
    "# WeightSpaceObject class for handling MLP weights\n",
    "class WeightSpaceObject:\n",
    "    def __init__(self, weights, biases):\n",
    "        self.weights = weights if isinstance(weights, tuple) else tuple(weights)\n",
    "        self.biases = biases if isinstance(biases, tuple) else tuple(biases)\n",
    "        \n",
    "    def flatten(self, device=None):\n",
    "        \"\"\"Flatten weights and biases into a single vector\"\"\"\n",
    "        flat = torch.cat([w.flatten() for w in self.weights] + \n",
    "                          [b.flatten() for b in self.biases])\n",
    "        if device:\n",
    "            flat = flat.to(device)\n",
    "        return flat\n",
    "    \n",
    "    @classmethod\n",
    "    def from_flat(cls, flat, layers, device):\n",
    "        \"\"\"Create WeightSpaceObject from flattened vector\"\"\"\n",
    "        sizes = []\n",
    "        # Calculate sizes for weight matrices\n",
    "        for i in range(len(layers) - 1):\n",
    "            sizes.append(layers[i] * layers[i+1])  # Weight matrix\n",
    "        # Calculate sizes for bias vectors\n",
    "        for i in range(1, len(layers)):\n",
    "            sizes.append(layers[i])  # Bias vector\n",
    "            \n",
    "        # Split flat tensor into parts\n",
    "        parts = []\n",
    "        start = 0\n",
    "        for size in sizes:\n",
    "            parts.append(flat[start:start+size])\n",
    "            start += size\n",
    "            \n",
    "        # Reshape into weight matrices and bias vectors\n",
    "        weights = []\n",
    "        biases = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            w_size = layers[i] * layers[i+1]\n",
    "            weights.append(parts[i].reshape(layers[i+1], layers[i]))\n",
    "            biases.append(parts[i + len(layers) - 1])\n",
    "            \n",
    "        return cls(weights, biases).to(device)\n",
    "    \n",
    "    def to(self, device):\n",
    "        \"\"\"Move weights and biases to specified device\"\"\"\n",
    "        weights = tuple(w.to(device) for w in self.weights)\n",
    "        biases = tuple(b.to(device) for b in self.biases)\n",
    "        return WeightSpaceObject(weights, biases)\n",
    "        \n",
    "    def map(self, fn):\n",
    "        new_weights = tuple(fn(w) for w in self.weights)\n",
    "        new_biases = tuple(fn(b) for b in self.biases)\n",
    "        return WeightSpaceObject(new_weights, new_biases)\n",
    "\n",
    "# Simple Bunch class for storing data\n",
    "class Bunch:\n",
    "    def __init__(self, **kwargs):\n",
    "        self.__dict__.update(kwargs)\n",
    "\n",
    "# Safe deflatten function that checks bounds before accessing tensors\n",
    "def safe_deflatten(flat, batch_size, starts, ends):\n",
    "    \"\"\"Safely deflatten a tensor without index errors\"\"\"\n",
    "    parts = []\n",
    "    actual_batch_size = flat.size(0)\n",
    "    \n",
    "    # Ensure we don't exceed the actual batch size\n",
    "    safe_batch_size = min(actual_batch_size, batch_size)\n",
    "    \n",
    "    for i in range(safe_batch_size):\n",
    "        batch_parts = []\n",
    "        for si, ei in zip(starts, ends):\n",
    "            if si < ei:  # Only process valid ranges\n",
    "                batch_parts.append(flat[i][si:ei])\n",
    "        parts.append(batch_parts)\n",
    "    \n",
    "    return parts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dba2e87c-c0d4-42ad-b9d5-781c0da1106e",
   "metadata": {},
   "source": [
    "# Flow matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd436e-0ba7-4470-983c-bc876fc911b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = MNIST or Fashion MNIST\n",
    "ref_model, original_models, mnist_permuted_models = get_permuted_models_data(ref_point=0, model_type = \"MNIST\")\n",
    "ref_model, original_models, fmnist_permuted_models = get_permuted_models_data(ref_point=0, model_type = \"Fashion MNIST\")\n",
    "\n",
    "layer_layout = [196, 32, 32, 10]  # MLP architecture for MNIST\n",
    "\n",
    "# Create WSO objects from permuted models\n",
    "logging.info(\"Converting MNIST models to WeightSpaceObjects...\")\n",
    "mnist_weights_list = []\n",
    "for model in tqdm(mnist_permuted_models):\n",
    "    weights = (\n",
    "        model.fc1.weight.data.clone(),\n",
    "        model.fc2.weight.data.clone(),\n",
    "        model.fc3.weight.data.clone()\n",
    "    )\n",
    "    \n",
    "    biases = (\n",
    "        model.fc1.bias.data.clone(),\n",
    "        model.fc2.bias.data.clone(), \n",
    "        model.fc3.bias.data.clone()\n",
    "    )\n",
    "    \n",
    "    wso = WeightSpaceObject(weights, biases)\n",
    "    mnist_weights_list.append(wso)\n",
    "\n",
    "logging.info(\"Converting Fashion MNIST models to WeightSpaceObjects...\")\n",
    "fmnist_weights_list = []\n",
    "for model in tqdm(fmnist_permuted_models):\n",
    "    weights = (\n",
    "        model.fc1.weight.data.clone(),\n",
    "        model.fc2.weight.data.clone(),\n",
    "        model.fc3.weight.data.clone()\n",
    "    )\n",
    "    \n",
    "    biases = (\n",
    "        model.fc1.bias.data.clone(),\n",
    "        model.fc2.bias.data.clone(), \n",
    "        model.fc3.bias.data.clone()\n",
    "    )\n",
    "    \n",
    "    wso = WeightSpaceObject(weights, biases)\n",
    "    fmnist_weights_list.append(wso)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef298a6-d8e1-4e10-870b-9c34f1f715f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create flat vectors\n",
    "# logging.info(\"Converting to flat tensors...\")\n",
    "\n",
    "flat_mnist_target_weights = torch.stack([wso.flatten(device) for wso in mnist_weights_list])\n",
    "mnist_labels = torch.full([flat_mnist_target_weights.shape[0], 1], 0)\n",
    "\n",
    "flat_fmnist_target_weights = torch.stack([wso.flatten(device) for wso in fmnist_weights_list])\n",
    "fmnist_labels = torch.full([flat_fmnist_target_weights.shape[0], 1], 1)\n",
    "\n",
    "mnist_target_dataset = TensorDataset(flat_mnist_target_weights, mnist_labels)\n",
    "fmnist_target_dataset = TensorDataset(flat_fmnist_target_weights, fmnist_labels)\n",
    "\n",
    "from torch.utils.data import ConcatDataset\n",
    "def collate_fn(batch):\n",
    "    # batch is a list of (flat, label)\n",
    "    # We’ll sample pairs _within_ the same label to do conditional flow matching:\n",
    "    flats, labs = zip(*batch)\n",
    "    flats = torch.stack(flats)  # [B, flat_dim]\n",
    "    labs  = torch.stack(labs)   # [B]\n",
    "    return flats, labs\n",
    "\n",
    "batch_size = 32\n",
    "targetloader = DataLoader(\n",
    "    ConcatDataset([mnist_target_dataset, fmnist_target_dataset]), \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=collate_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "579c5346-c83d-4873-ac44-1e6f1ae733be",
   "metadata": {},
   "source": [
    "# Multiclass CFM time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2253af-3eb3-46b3-9751-c49d0b140a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from types import SimpleNamespace\n",
    "\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_dim, out_dim):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(in_dim, out_dim)\n",
    "        self.norm = nn.LayerNorm(out_dim)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.residual = (in_dim == out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.norm( self.activation(self.linear(x)) )\n",
    "        if self.residual:\n",
    "            return out + x\n",
    "        return out\n",
    "\n",
    "class TimeConditionedMLP(nn.Module):\n",
    "    \"\"\"\n",
    "    A conditional flow network that takes:\n",
    "      - x ∈ ℝ^{flat_dim}\n",
    "      - t ∈ ℝ (scalar in [0,1], shaped as [B,1])\n",
    "      - c ∈ {0,1,…,num_classes−1} (class labels)\n",
    "\n",
    "    and returns a predicted velocity in ℝ^{flat_dim}. Internally:\n",
    "      • We embed t via a small MLP (time_embed).\n",
    "      • We embed c via nn.Embedding.\n",
    "      • We concatenate (x, t_embed, c_embed) → pass through two hidden layers → output dimension flat_dim.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        flat_dim: int,\n",
    "        t_embed_dim: int,\n",
    "        class_embed_dim: int,\n",
    "        num_classes: int,\n",
    "        hidden_dim: int = 512,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.flat_dim = flat_dim\n",
    "        self.t_embed_dim = t_embed_dim\n",
    "        self.class_embed_dim = class_embed_dim\n",
    "        self.num_classes = num_classes\n",
    "        self.hidden_dim = hidden_dim\n",
    "\n",
    "        # 1) Time embedding network: ℝ → ℝ^{t_embed_dim}\n",
    "        self.time_embed = nn.Sequential(\n",
    "            nn.Linear(1, t_embed_dim),\n",
    "        )\n",
    "\n",
    "        # 2) Class embedding: maps {0,…,num_classes−1} → ℝ^{class_embed_dim}\n",
    "        self.class_emb = nn.Embedding(num_classes, class_embed_dim)\n",
    "\n",
    "        # 3) Main MLP: input dim = flat_dim + t_embed_dim + class_embed_dim\n",
    "        in_dim = flat_dim + t_embed_dim + class_embed_dim\n",
    "\n",
    "        layers = []\n",
    "        prev_dim = in_dim\n",
    "        for hidden_dim in hidden_dims:\n",
    "            layers.append(ResidualBlock(prev_dim, hidden_dim))\n",
    "            prev_dim = hidden_dim\n",
    "            \n",
    "        self.hidden_layers = nn.Sequential(*layers)\n",
    "        self.output_layer = nn.Linear(prev_dim, flat_dim)\n",
    "\n",
    "    def forward(self, x: torch.Tensor, t: torch.Tensor, c: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "          x : Tensor of shape [B, flat_dim]\n",
    "          t : Tensor of shape [B, 1]  (scalar time per sample)\n",
    "          c : LongTensor of shape [B] (class labels in {0,...,num_classes-1})\n",
    "\n",
    "        Returns:\n",
    "          velocity_pred : Tensor of shape [B, flat_dim]\n",
    "        \"\"\"\n",
    "        # 1) Compute time embeddings\n",
    "        #    t is [B, 1], pass through time_embed → [B, t_embed_dim]\n",
    "        t_emb = self.time_embed(t)\n",
    "\n",
    "        # 2) Compute class embeddings\n",
    "        #    c is [B], pass through nn.Embedding → [B, class_embed_dim]\n",
    "        c_emb = self.class_emb(c)\n",
    "\n",
    "        # 3) Concatenate along feature dimension → [B, flat_dim + t_embed_dim + class_embed_dim]\n",
    "        xcat = torch.cat([x, t_emb, c_emb], dim=-1)\n",
    "\n",
    "        # 4) Forward through two hidden layers\n",
    "        x = self.hidden_layers(xcat)\n",
    "        return self.output_layer(x)\n",
    "\n",
    "\n",
    "class SimpleCFM:\n",
    "    def __init__(\n",
    "        self,\n",
    "        targetloader: torch.utils.data.DataLoader,\n",
    "        model: TimeConditionedMLP,\n",
    "        layer_layout,\n",
    "        fm_type: str = \"vanilla\",\n",
    "        mode: str = \"velocity\",\n",
    "        t_dist: str = \"uniform\",\n",
    "        device: torch.device = None,\n",
    "        normalize_pred: bool = False,\n",
    "        geometric: bool = False,\n",
    "        source_std: float = 0.001,   # standard deviation for on-the-fly noise\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "          targetloader   : DataLoader yielding (flat_tensor, label) for the “target” weight-space objects.\n",
    "                           We assume `label ∈ {0,1}`.  On each iteration we draw exactly one batch from here.\n",
    "          model          : A TimeConditionedMLP instance (flat_dim + time + class → velocity).\n",
    "          layer_layout   : np.array describing layer sizes—(kept for legacy, not used directly here).\n",
    "          fm_type        : “vanilla” or “ot”—ignored for now.\n",
    "          mode           : “velocity” or “ot”—we implement only velocity-mode here.\n",
    "          t_dist         : “uniform” or “beta”—we sample t ~ Uniform(0,1) for now.\n",
    "          device         : torch.device (“cuda” or “cpu”).\n",
    "          normalize_pred : If True, normalize predicted velocity to unit norm (optional).\n",
    "          geometric      : If True, use geometric interpolation (not implemented; we use linear).\n",
    "          source_std     : float ≥0, the σ used for on-the-fly Gaussian noise in ℝ^{flat_dim}.\n",
    "        \"\"\"\n",
    "        self.targetloader = targetloader\n",
    "        self.model        = model.to(device)\n",
    "        self.layer_layout = layer_layout\n",
    "        self.fm_type      = fm_type\n",
    "        self.mode         = mode\n",
    "        self.t_dist       = t_dist\n",
    "        self.device       = device if device is not None else torch.device(\"cpu\")\n",
    "        self.normalize_pred = normalize_pred \n",
    "        self.geometric    = geometric\n",
    "        self.source_std   = source_std\n",
    "\n",
    "        self.metrics      = {\"train_loss\": [], \"time\": []}\n",
    "        self.best_loss    = float(\"inf\")\n",
    "        self.best_model_state = None\n",
    "\n",
    "        # We will need an iterator over targetloader:\n",
    "        self._target_iter = iter(self.targetloader)\n",
    "\n",
    "    def sample_from_loader(self):\n",
    "        \"\"\"\n",
    "        Sample one minibatch from targetloader, then generate a matching 'source' noise batch\n",
    "        with exactly the same labels.  Returns a ‘flow’ namespace with attributes:\n",
    "\n",
    "          flow.xt          : [B, flat_dim]   = x₀ + t*(x₁ − x₀)\n",
    "          flow.t           : [B, 1]          = the sampled t ∼ Uniform(0,1)\n",
    "          flow.true_flow   : [B, flat_dim]   = (x₁ − x₀)\n",
    "          flow.class_label : [B] (long)      = class label (0 or 1) for each pair\n",
    "        \"\"\"\n",
    "        try:\n",
    "            flats1, labs1 = next(self._target_iter)\n",
    "        except StopIteration:\n",
    "            # re‐create the iterator if we hit the end\n",
    "            self._target_iter = iter(self.targetloader)\n",
    "            flats1, labs1 = next(self._target_iter)\n",
    "\n",
    "        flats1 = flats1.to(self.device)  # [B, flat_dim]\n",
    "        labs1  = labs1.squeeze(-1).to(self.device).long()  # [B], ensure type=long\n",
    "\n",
    "        B, flat_dim = flats1.shape\n",
    "\n",
    "        # 1) On‐the‐fly: generate x₀ (noise) for each sample in this batch\n",
    "        #    We simply sample from N(0, source_std²) in ℝ^{flat_dim}:\n",
    "        #    shape = [B, flat_dim]\n",
    "        #    If you wanted to make the noise distribution depend on 'labs1', you could\n",
    "        #    do two separate Gaussian draws.  But we assume just diagonal Gaussian noise\n",
    "        #    works for both classes.\n",
    "        x0 = torch.randn(B, flat_dim, device=self.device) * self.source_std\n",
    "\n",
    "        # 2) Sample t ∼ Uniform(0,1) for each sample\n",
    "        t = torch.rand(B, 1, device=self.device)  # [B,1]\n",
    "\n",
    "        # 3) Compute linear interpolation: xₜ = x₀ + t*(x₁ − x₀)\n",
    "        xt = x0 + t * (flats1 - x0)  # [B, flat_dim]\n",
    "\n",
    "        # 4) The ‘true_flow’ is (x₁ - x₀)\n",
    "        true_flow = (flats1 - x0)    # [B, flat_dim]\n",
    "\n",
    "        # 5) Build the SimpleNamespace\n",
    "        flow = SimpleNamespace()\n",
    "        flow.xt          = xt             # [B, flat_dim]\n",
    "        flow.t           = t              # [B, 1]\n",
    "        flow.true_flow   = true_flow      # [B, flat_dim]\n",
    "        flow.class_label = labs1          # [B] (long tensor, values ∈ {0,1})\n",
    "\n",
    "        return flow\n",
    "\n",
    "    def forward(self, flow: SimpleNamespace) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Given a flow struct (xt, t, class_label), returns the predicted velocity\n",
    "        => model(xt, t, class_label) ∈ ℝ^{flat_dim}.\n",
    "        \"\"\"\n",
    "        x_t = flow.xt           # [B, flat_dim]\n",
    "        t   = flow.t            # [B, 1]\n",
    "        c   = flow.class_label  # [B]\n",
    "\n",
    "        pred = self.model(x_t, t, c)  # [B, flat_dim]\n",
    "\n",
    "        if self.normalize_pred:\n",
    "            norm = pred.norm(dim=-1, keepdim=True).clamp(min=1e-6)\n",
    "            pred = pred / norm\n",
    "\n",
    "        return pred\n",
    "        \n",
    "    # def loss_fn(self, flow_pred, flow):\n",
    "    #     \"\"\"Compute loss between predicted and true flows\"\"\"\n",
    "    #     if self.mode == \"target\":\n",
    "    #         l_flow = torch.mean((flow_pred.squeeze() - flow.x1) ** 2)\n",
    "    #     elif self.mode == \"velocity\":\n",
    "    #         l_flow = torch.mean((flow_pred.squeeze() - flow.ut) ** 2)\n",
    "    #     elif self.fm_type == \"ot\":\n",
    "    #         l_flow = torch.mean((flow_pred.squeeze() - flow.ut) ** 2)\n",
    "    #     else:\n",
    "    #         # Fallback to velocity mode if unknown\n",
    "    #         l_flow = torch.mean((flow_pred.squeeze() - flow.ut) ** 2)\n",
    "    #     return None, l_flow\n",
    "        \n",
    "    def train(self, n_iters: int, optimizer: torch.optim.Optimizer, sigma: float = 0.0):\n",
    "        \"\"\"\n",
    "        Run n_iters of conditional flow‐matching training. At each iteration:\n",
    "          1) Sample a minibatch → flow = sample_from_loader()\n",
    "          2) pred_flow = forward(flow)\n",
    "          3) loss = ||pred_flow − true_flow||²₂\n",
    "          4) backward & step\n",
    "        \"\"\"\n",
    "        self.model.train()\n",
    "        for it in range(1, n_iters + 1):\n",
    "            flow      = self.sample_from_loader()\n",
    "            pred_flow = self.forward(flow)             # [B, flat_dim]\n",
    "            true_flow = flow.true_flow                 # [B, flat_dim]\n",
    "\n",
    "            # update loss function to a transport map, target, velocity, ot, etc\n",
    "            loss = F.mse_loss(pred_flow, true_flow)    # scalar - replaces velocity setting\n",
    "            # _, loss = self.loss_fn(pred_flow, true_flow)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            self.metrics[\"train_loss\"].append(loss.item())\n",
    "            if it % 100 == 0 or it == n_iters:\n",
    "                print(f\"[Iter {it:5d}/{n_iters:5d}]  Loss = {loss.item():.6f}\")\n",
    "                \n",
    "                checkpoint_dir = 'checkpoints'\n",
    "                os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "                ckpt_path = os.path.join(checkpoint_dir, f'linear_cfm_{it}.pth') # changed!\n",
    "                torch.save(self.model.state_dict(), ckpt_path)\n",
    "\n",
    "            if loss.item() < self.best_loss:\n",
    "                self.best_loss = loss.item()\n",
    "                self.best_model_state = {\n",
    "                    \"model\":     self.model.state_dict(),\n",
    "                    \"optimizer\": optimizer.state_dict(),\n",
    "                    \"iteration\": it,\n",
    "                }\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def map(\n",
    "        self,\n",
    "        random_flat: torch.Tensor,\n",
    "        class_label: torch.Tensor,\n",
    "        n_steps: int = 100,\n",
    "        noise_scale: float = 0.0,\n",
    "    ) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Generate new weight-space samples conditioned on a given class label by integrating\n",
    "        from t=0 → t=1 using the learned velocity network.\n",
    "\n",
    "        Args:\n",
    "          random_flat  : [B, flat_dim] initial “noise” at t=0\n",
    "          class_label  : [B]        long tensor ∈ {0,1}\n",
    "          n_steps      : int, # of Euler steps\n",
    "          noise_scale  : float, added Gaussian noise at each step (optional)\n",
    "\n",
    "        Returns:\n",
    "          x : [B, flat_dim] final mapped weights\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        x = random_flat.to(self.device)          # [B, flat_dim]\n",
    "        # c = self.model.class_emb(class_label).to(self.device).long()\n",
    "        c = class_label.to(self.device).long()   # [B]\n",
    "\n",
    "        dt = 1.0 / float(n_steps)\n",
    "        for i in range(n_steps):\n",
    "            # Compute tᵢ = i / n_steps\n",
    "            t_i = torch.full((x.shape[0], 1), float(i) / float(n_steps), device=self.device)\n",
    "\n",
    "            # Predict velocity vᵢ = model(xᵢ, tᵢ, c)\n",
    "            v = self.model(x, t_i, c)          # [B, flat_dim]\n",
    "\n",
    "            # Euler update: x ← x + v * dt\n",
    "            x = x + v * dt\n",
    "\n",
    "            if noise_scale > 0.0:\n",
    "                x = x + noise_scale * torch.randn_like(x)\n",
    "\n",
    "        return x  # [B, flat_dim]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfef4059-3a5b-4f56-9aa1-bc9ed976fc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_dim        = flat_mnist_target_weights.shape[1]\n",
    "t_embed_dim     = 16         # e.g. choose 16\n",
    "class_embed_dim = 64         # size of class embedding (tunable)\n",
    "num_classes     = 2          # MNIST vs. FashionMNIST\n",
    "hidden_dims     = [4096, 2048, 2048, 4096]\n",
    "\n",
    "flow_net = TimeConditionedMLP(\n",
    "    flat_dim=flat_dim,\n",
    "    t_embed_dim=t_embed_dim,\n",
    "    class_embed_dim=class_embed_dim,\n",
    "    num_classes=num_classes,\n",
    "    hidden_dim=hidden_dims\n",
    ").to(device)\n",
    "\n",
    "# # Set to training mode\n",
    "flow_net.train()\n",
    "\n",
    "# Count parameters\n",
    "n_params_base = sum(p.numel() for p in MLP().parameters())\n",
    "n_params_flow = count_parameters(flow_net)\n",
    "logging.info(f\"MLP params:{n_params_base}\")\n",
    "logging.info(f\"Flow model params:{n_params_flow}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d195eca-01e8-4cc5-ad87-b360314bcb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Instantiate SimpleCFM with only targetloader\n",
    "cfm = SimpleCFM(\n",
    "    targetloader   = targetloader,\n",
    "    model          = flow_net,\n",
    "    layer_layout   = layer_layout, # just to keep the old API happy\n",
    "    fm_type        = \"vanilla\",\n",
    "    mode           = \"velocity\",\n",
    "    t_dist         = \"uniform\",\n",
    "    device         = device,\n",
    "    normalize_pred = True, # consider setting to true?\n",
    "    geometric      = False, # doesn't do anything right now\n",
    "    source_std     = 0.001, # match whatever you used beforehyperparameter tuning, 0.001 worked for single class CFM\n",
    ")\n",
    "\n",
    "optimizer = torch.optim.Adam(flow_net.parameters(), lr=1e-4) # Adam vs AdamW\n",
    "# cfm.train(n_iters=10000, optimizer=optimizer, sigma=0.01)\n",
    "# cfm.plot_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f2e4b7-ab63-46d6-a030-e5f548a36fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = 'checkpoints'\n",
    "load_it = 4500\n",
    "last_checkpoint = os.path.join(checkpoint_dir, f'linear_cfm_{load_it}.pth')\n",
    "\n",
    "\n",
    "# Re-instantiate model with same architecture\n",
    "\n",
    "flat_dim        = flat_mnist_target_weights.shape[1]\n",
    "t_embed_dim     = 16         # e.g. choose 16\n",
    "class_embed_dim = 64         # size of class embedding (tunable)\n",
    "num_classes     = 2          # MNIST vs. FashionMNIST\n",
    "hidden_dims     = [4096, 2048, 2048, 4096]\n",
    "\n",
    "flow_net = TimeConditionedMLP(\n",
    "    flat_dim=flat_dim,\n",
    "    t_embed_dim=t_embed_dim,\n",
    "    class_embed_dim=class_embed_dim,\n",
    "    num_classes=num_classes,\n",
    "    hidden_dim=hidden_dims\n",
    ").to(device)\n",
    "\n",
    "flow_net.load_state_dict(torch.load(last_checkpoint))\n",
    "flow_net.eval()\n",
    "print(f\"Loaded checkpoint from '{last_checkpoint}'\")\n",
    "\n",
    "cfm = SimpleCFM(\n",
    "    targetloader   = targetloader,\n",
    "    model          = flow_net,\n",
    "    layer_layout   = layer_layout, # just to keep the old API happy\n",
    "    fm_type        = \"vanilla\",\n",
    "    mode           = \"velocity\",\n",
    "    t_dist         = \"uniform\",\n",
    "    device         = device,\n",
    "    normalize_pred = True, # consider setting to true?\n",
    "    geometric      = False, # doesn't do anything right now\n",
    "    source_std     = 0.001, # match whatever you used beforehyperparameter tuning, 0.001 worked for single class CFM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9f9765-3526-4d00-b8be-e76f52a92e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# need to handle test_loader selection correctly. \n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((14, 14)),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset with the downsampling transform\n",
    "mnist_train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=mnist_transform)\n",
    "mnist_test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=mnist_transform)\n",
    "\n",
    "# Create data loaders\n",
    "mnist_train_loader = torch.utils.data.DataLoader(mnist_train_dataset, batch_size=64, shuffle=True)\n",
    "mnist_test_loader = torch.utils.data.DataLoader(mnist_test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "# Resize (14x14) and Normalize Fashion MNIST images from torch.vision then create dataset and dataloader\n",
    "fashion_mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Resize((14, 14)),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load the MNIST dataset with the downsampling transform\n",
    "fashion_mnist_train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=fashion_mnist_transform)\n",
    "fashion_mnist_test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=fashion_mnist_transform)\n",
    "\n",
    "# Create data loaders\n",
    "fashion_mnist_train_loader = torch.utils.data.DataLoader(fashion_mnist_train_dataset, batch_size=64, shuffle=True)\n",
    "fashion_mnist_test_loader = torch.utils.data.DataLoader(fashion_mnist_test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a7274c-e3d6-4f73-b3dd-f3b484f610d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new MLP weights\n",
    "logging.info(\"Generating new MLP weights...\")\n",
    "n_samples = 10\n",
    "\n",
    "generate_type = 1 # 0 MNIST, 1 Fashion MNIST\n",
    "source_std = cfm.source_std\n",
    "random_flat = torch.randn(n_samples, flat_dim, device=device) * source_std\n",
    "class_labels = torch.full([n_samples], generate_type, dtype=torch.long, device=device)#.unsqueeze(0) # 0 for MNIST and 1 for Fashion MNIST\n",
    "\n",
    "new_weights_flat = cfm.map(\n",
    "    random_flat, \n",
    "    class_labels,\n",
    "    n_steps=100,\n",
    "    noise_scale=0.001\n",
    ")\n",
    "\n",
    "\n",
    "if generate_type == 0:\n",
    "    test_loader = mnist_test_loader\n",
    "else: \n",
    "    test_loader = fashion_mnist_test_loader\n",
    "    \n",
    "# Convert to MLP weights and save\n",
    "accuracies = []\n",
    "for i in range(n_samples):\n",
    "    new_wso = WeightSpaceObject.from_flat(\n",
    "        new_weights_flat[i], \n",
    "        layers=np.array(layer_layout), \n",
    "        device=device\n",
    "    )\n",
    "\n",
    "    expected_weight_shapes = [(32, 196), (32, 32), (10, 32)]\n",
    "    expected_bias_shapes = [(32,), (32,), (10,)]\n",
    "\n",
    "    assert len(new_wso.weights) == 3, f\"Expected 3 weight matrices, got {len(new_wso.weights)}\"\n",
    "    assert len(new_wso.biases) == 3, f\"Expected 3 bias vectors, got {len(new_wso.biases)}\"\n",
    "    \n",
    "    # Check each weight and bias shape\n",
    "    for j, (w, expected_shape) in enumerate(zip(new_wso.weights, expected_weight_shapes)):\n",
    "        assert w.shape == expected_shape, f\"Weight {j} has shape {w.shape}, expected {expected_shape}\"\n",
    "    \n",
    "    for j, (b, expected_shape) in enumerate(zip(new_wso.biases, expected_bias_shapes)):\n",
    "        assert b.shape == expected_shape, f\"Bias {j} has shape {b.shape}, expected {expected_shape}\"\n",
    "\n",
    "    # Save the generated weights\n",
    "    # torch.save(\n",
    "    #     (new_wso.weights, new_wso.biases),\n",
    "    #     f\"generated_mlp_weights_{i}.pt\"\n",
    "    # )\n",
    "\n",
    "    # Create and test model\n",
    "    model = MLP()\n",
    "    model.fc1.weight.data = new_wso.weights[0].clone()\n",
    "    model.fc1.bias.data = new_wso.biases[0].clone()\n",
    "    model.fc2.weight.data = new_wso.weights[1].clone()\n",
    "    model.fc2.bias.data = new_wso.biases[1].clone()\n",
    "    model.fc3.weight.data = new_wso.weights[2].clone()\n",
    "    model.fc3.bias.data = new_wso.biases[2].clone()\n",
    "\n",
    "    acc = test_mlp(model, test_loader)\n",
    "    accuracies.append(acc)\n",
    "    title_type = 0\n",
    "    if generate_type == 0:  title_type = f\"MNIST\" \n",
    "    else: title_type = f\"Fashion MNIST\"\n",
    "        \n",
    "    logging.info(f\"Generated { title_type } MLP {i} accuracy: {acc:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f34e67c-f2a5-400d-9e43-81dd77936adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8), dpi=80)\n",
    "plt.hist(accuracies, alpha = 0.8)\n",
    "plt.axvline(np.mean(accuracies), color = 'k', label = f\"Mean generated {n_samples} model(s) performance\")\n",
    "plt.axvline(np.mean(accuracies) + np.std(accuracies), color = 'k', linestyle = '--', label = f\"+1 Deviation performance\")\n",
    "plt.axvline(np.mean(accuracies) - np.std(accuracies), color = 'k', linestyle = '--', label = f\"-1 Deviation performance\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84603b0a-8890-4b76-92eb-9deb7492bb46",
   "metadata": {},
   "source": [
    "# Hybrid Embeddings: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e5bafb2-9f89-43c8-a965-6cd72cac0427",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Generate new MLP weights\n",
    "logging.info(\"Generating new MLP weights...\")\n",
    "n_samples = 5\n",
    "n_steps = 100\n",
    "generate_types = [0.98, 0.9825, 0.985, 0.9875, 0.99, 0.9925, 0.995, 0.9975, 1] # 0 MNIST, 1 Fashion MNIST\n",
    "\n",
    "for generate_type in generate_types: \n",
    "    \n",
    "    source_std = 0.001\n",
    "    random_flat = torch.randn(n_samples, flat_dim, device=device) * source_std\n",
    "    class_labels = torch.full([n_samples], generate_type, dtype=torch.long, device=device)#.unsqueeze(0) # 0 for MNIST and 1 for Fashion MNIST\n",
    "    \n",
    "    new_weights_flat = cfm.map(\n",
    "        random_flat, \n",
    "        class_labels,\n",
    "        n_steps=n_steps,\n",
    "        noise_scale=0.001\n",
    "    )\n",
    "    # Convert to MLP weights and save\n",
    "    mnist_accuracies = []\n",
    "    fashion_mnist_accuracies = []\n",
    "    \n",
    "    for i in range(n_samples):\n",
    "        new_wso = WeightSpaceObject.from_flat(\n",
    "            new_weights_flat[i], \n",
    "            layers=np.array(layer_layout), \n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "        expected_weight_shapes = [(32, 196), (32, 32), (10, 32)]\n",
    "        expected_bias_shapes = [(32,), (32,), (10,)]\n",
    "    \n",
    "        assert len(new_wso.weights) == 3, f\"Expected 3 weight matrices, got {len(new_wso.weights)}\"\n",
    "        assert len(new_wso.biases) == 3, f\"Expected 3 bias vectors, got {len(new_wso.biases)}\"\n",
    "        \n",
    "        # Check each weight and bias shape\n",
    "        for j, (w, expected_shape) in enumerate(zip(new_wso.weights, expected_weight_shapes)):\n",
    "            assert w.shape == expected_shape, f\"Weight {j} has shape {w.shape}, expected {expected_shape}\"\n",
    "        \n",
    "        for j, (b, expected_shape) in enumerate(zip(new_wso.biases, expected_bias_shapes)):\n",
    "            assert b.shape == expected_shape, f\"Bias {j} has shape {b.shape}, expected {expected_shape}\"\n",
    "    \n",
    "        # Create and test model\n",
    "        model = MLP()\n",
    "        model.fc1.weight.data = new_wso.weights[0].clone()\n",
    "        model.fc1.bias.data = new_wso.biases[0].clone()\n",
    "        model.fc2.weight.data = new_wso.weights[1].clone()\n",
    "        model.fc2.bias.data = new_wso.biases[1].clone()\n",
    "        model.fc3.weight.data = new_wso.weights[2].clone()\n",
    "        model.fc3.bias.data = new_wso.biases[2].clone()\n",
    "    \n",
    "        mnist_acc = test_mlp(model, mnist_test_loader)\n",
    "        mnist_accuracies.append(mnist_acc)\n",
    "\n",
    "        fmnist_acc = test_mlp(model, fashion_mnist_test_loader)\n",
    "        fashion_mnist_accuracies.append(fmnist_acc)\n",
    "            \n",
    "        logging.info(f\"Generated { generate_type } labeled MLP {i} accuracies: MNIST: {mnist_acc:.2f}%  Fashion MNIST: {fmnist_acc:.2f}%\")\n",
    "    print(f\"--- Generated type {generate_type} stats: avg MNIST: {np.mean(mnist_accuracies):.2f}%, avg Fashion MNIST: {np.mean(fashion_mnist_accuracies):.2f}% ---\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb57976-c8c0-4bda-9445-d589ff9a45f8",
   "metadata": {},
   "source": [
    "# Width projection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c208957d-0957-437d-bada-5ec988ecd553",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# gc = torch.cuda.empty_cache if torch.cuda.is_available() else lambda: None\n",
    "\n",
    "def collect_all_neurons(\n",
    "    diffusion_model, #\n",
    "    scheduler, #\n",
    "    gae, #\n",
    "    template, #\n",
    "    class_label,\n",
    "    latent_dim, #\n",
    "    N_nodes, #\n",
    "    num_samples: int,\n",
    "    n_in: int,\n",
    "    n_hid: int,\n",
    "    n_out: int,\n",
    "    device: torch.device\n",
    ") -> (np.ndarray, np.ndarray):\n",
    "    \"\"\"\n",
    "    Sample `num_samples` small MLPs via the latent diffusion model, decode them,\n",
    "    and extract joint parameter vectors for each hidden neuron in both hidden layers.\n",
    "\n",
    "    Each hidden neuron is represented by:\n",
    "      - Layer1 neurons: [W1_row (n_in), b1 (1), W2_column (n_hid)]\n",
    "      - Layer2 neurons: [W2_row (n_hid), b2 (1), W3_column (n_out)]\n",
    "\n",
    "    Returns:\n",
    "      L1: np.ndarray of shape [num_samples * n_hid, n_in + 1 + n_hid]\n",
    "      L2: np.ndarray of shape [num_samples * n_hid, n_hid + 1 + n_out]\n",
    "    \"\"\"\n",
    "    layer1_neurons = []\n",
    "    layer2_neurons = []\n",
    "\n",
    "    # Ensure models are in eval mode for deterministic behavior\n",
    "    diffusion_model.eval()\n",
    "    gae.eval()\n",
    "\n",
    "    for _ in range(num_samples):\n",
    "        # 1) Sample a single latent graph\n",
    "        z = sample_latents_2d_cond(\n",
    "            diffusion_model,\n",
    "            scheduler,\n",
    "            num_graphs=1,\n",
    "            N_nodes=N_nodes,\n",
    "            latent_dim=latent_dim,  # placeholder\n",
    "            device=device,\n",
    "            class_label=class_label\n",
    "        )[0].to(device)\n",
    "\n",
    "        # 2) Decode latent to graph predictions, then to an MLP\n",
    "        edge_pred, node_pred = gae.decoder(\n",
    "            z,\n",
    "            template.edge_index,\n",
    "            template.edge_attr.view(-1).to(device)\n",
    "        )\n",
    "        mlp = vgae_to_mlp(Data(\n",
    "            x=node_pred.unsqueeze(1),\n",
    "            edge_index=template.edge_index,\n",
    "            edge_attr=edge_pred.unsqueeze(1),\n",
    "        ))\n",
    "\n",
    "        # 3) Extract weight and bias arrays\n",
    "        W1 = mlp.fc1.weight.data.cpu().numpy()  # shape [n_hid, n_in]\n",
    "        b1 = mlp.fc1.bias.data.cpu().numpy()    # shape [n_hid]\n",
    "        W2 = mlp.fc2.weight.data.cpu().numpy()  # shape [n_hid, n_hid]\n",
    "        b2 = mlp.fc2.bias.data.cpu().numpy()    # shape [n_hid]\n",
    "        W3 = mlp.fc3.weight.data.cpu().numpy()  # shape [n_out, n_hid]\n",
    "\n",
    "        # 4) Collect neuron vectors for both layers\n",
    "        for i in range(n_hid):\n",
    "            # incoming to layer1, bias1, outgoing from layer1 to layer2\n",
    "            v1 = np.concatenate([W1[i], [b1[i]], W2[:, i]])\n",
    "            layer1_neurons.append(v1)\n",
    "        for j in range(n_hid):\n",
    "            # incoming to layer2, bias2, outgoing from layer2 to output\n",
    "            v2 = np.concatenate([W2[j, :], [b2[j]], W3[:, j]])\n",
    "            layer2_neurons.append(v2)\n",
    "\n",
    "        # optional cache cleanup\n",
    "        # gc.collect()\n",
    "        # if torch.cuda.is_available():\n",
    "        #     gc()\n",
    "\n",
    "    return np.stack(layer1_neurons, axis=0), np.stack(layer2_neurons, axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fccaedd5-1d8e-42cd-a605-b2477c3a5a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate new MLP weights\n",
    "logging.info(\"Generating new MLP weights...\")\n",
    "n_samples = 10\n",
    "\n",
    "generate_type = 1 # 0 MNIST, 1 Fashion MNIST\n",
    "source_std = cfm.source_std\n",
    "random_flat = torch.randn(n_samples, flat_dim, device=device) * source_std\n",
    "class_labels = torch.full([n_samples], generate_type, dtype=torch.long, device=device)#.unsqueeze(0) # 0 for MNIST and 1 for Fashion MNIST\n",
    "\n",
    "new_weights_flat = cfm.map(\n",
    "    random_flat, \n",
    "    class_labels,\n",
    "    n_steps=100,\n",
    "    noise_scale=0.001\n",
    ")\n",
    "new_weights_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19cc248b-d3c7-4bd3-990f-5fc9785736b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flat_mnist_target_weights.shape[1]\n",
    "# device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3741dac-8a7c-4a8a-88bb-c55f8c8d14b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def build_distribution(cfm, n_samples = 1, generate_type = 0, n_steps = 100, flat_dim = 7690, device = device):\n",
    "    \n",
    "    # model shape hyperparams\n",
    "    n_in=196\n",
    "    n_hid=32\n",
    "    n_out=10\n",
    "\n",
    "    # cfm\n",
    "    source_std = cfm.source_std\n",
    "    random_flat = torch.randn(n_samples, flat_dim, device=device) * source_std\n",
    "    class_labels = torch.full([n_samples], generate_type, dtype=torch.long, device=device)#.unsqueeze(0) # 0 for MNIST and 1 for Fashion MNIST\n",
    "    \n",
    "    new_weights_flat = cfm.map(\n",
    "        random_flat, \n",
    "        class_labels,\n",
    "        n_steps=n_steps,\n",
    "        noise_scale=source_std\n",
    "    )\n",
    "    \n",
    "    # Convert to MLP weights and save\n",
    "    layer1_neurons = []\n",
    "    layer2_neurons = []\n",
    "    for i in range(n_samples):\n",
    "        \n",
    "        new_wso = WeightSpaceObject.from_flat(\n",
    "            new_weights_flat[i], \n",
    "            layers=np.array(layer_layout), \n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "        expected_weight_shapes = [(32, 196), (32, 32), (10, 32)]\n",
    "        expected_bias_shapes = [(32,), (32,), (10,)]\n",
    "    \n",
    "        assert len(new_wso.weights) == 3, f\"Expected 3 weight matrices, got {len(new_wso.weights)}\"\n",
    "        assert len(new_wso.biases) == 3, f\"Expected 3 bias vectors, got {len(new_wso.biases)}\"\n",
    "        \n",
    "        # Check each weight and bias shape\n",
    "        for j, (w, expected_shape) in enumerate(zip(new_wso.weights, expected_weight_shapes)):\n",
    "            assert w.shape == expected_shape, f\"Weight {j} has shape {w.shape}, expected {expected_shape}\"\n",
    "        \n",
    "        for j, (b, expected_shape) in enumerate(zip(new_wso.biases, expected_bias_shapes)):\n",
    "            assert b.shape == expected_shape, f\"Bias {j} has shape {b.shape}, expected {expected_shape}\"\n",
    "    \n",
    "        # Create and test model\n",
    "        model = MLP()\n",
    "        model.fc1.weight.data = new_wso.weights[0].clone()\n",
    "        model.fc1.bias.data = new_wso.biases[0].clone()\n",
    "        model.fc2.weight.data = new_wso.weights[1].clone()\n",
    "        model.fc2.bias.data = new_wso.biases[1].clone()\n",
    "        model.fc3.weight.data = new_wso.weights[2].clone()\n",
    "        model.fc3.bias.data = new_wso.biases[2].clone()\n",
    "    \n",
    "        # 3) Extract weight and bias arrays\n",
    "        W1 = model.fc1.weight.data.cpu().numpy()  # shape [n_hid, n_in]\n",
    "        b1 = model.fc1.bias.data.cpu().numpy()    # shape [n_hid]\n",
    "        W2 = model.fc2.weight.data.cpu().numpy()  # shape [n_hid, n_hid]\n",
    "        b2 = model.fc2.bias.data.cpu().numpy()    # shape [n_hid]\n",
    "        W3 = model.fc3.weight.data.cpu().numpy()  # shape [n_out, n_hid]\n",
    "    \n",
    "        # 4) Collect neuron vectors for both layers\n",
    "        for i in range(n_hid):\n",
    "            # incoming to layer1, bias1, outgoing from layer1 to layer2\n",
    "            v1 = np.concatenate([W1[i], [b1[i]], W2[:, i]])\n",
    "            layer1_neurons.append(v1)\n",
    "        for j in range(n_hid):\n",
    "            # incoming to layer2, bias2, outgoing from layer2 to output\n",
    "            v2 = np.concatenate([W2[j, :], [b2[j]], W3[:, j]])\n",
    "            layer2_neurons.append(v2)\n",
    "    \n",
    "        return np.stack(layer1_neurons, axis=0), np.stack(layer2_neurons, axis=0)\n",
    "\n",
    "\n",
    "def build_mixeduse_from_two_pcas(\n",
    "    pca1,\n",
    "    mu1,\n",
    "    cov1,\n",
    "    pca2,\n",
    "    mu2,\n",
    "    cov2,\n",
    "    M: int,\n",
    "    n_in: int,\n",
    "    orig_hid: int,\n",
    "    n_out: int,\n",
    "    init_type: str = 'xavier',\n",
    "    seed: int = None,\n",
    "    device: torch.device = torch.device('cpu')\n",
    ") -> nn.Module:\n",
    "    \"\"\"\n",
    "    Construct a new MixedUseMLP with hidden dimension M by sampling neurons\n",
    "    from two PCA+Gaussian models:\n",
    "      - PCA1 models layer1 neuron joint distribution: size n_in + 1 + orig_hid\n",
    "      - PCA2 models layer2 neuron joint distribution: size orig_hid + 1 + n_out\n",
    "\n",
    "    Parameters:\n",
    "      pca1, mu1, cov1: PCA, mean, cov for layer1\n",
    "      pca2, mu2, cov2: PCA, mean, cov for layer2\n",
    "      M: new hidden layer size\n",
    "      n_in: input dimension\n",
    "      orig_hid: original hidden size used in PCA\n",
    "      n_out: output dimension\n",
    "      init_type: weight init for layer2 fallback\n",
    "      seed: random seed for reproducibility\n",
    "      device: torch device\n",
    "\n",
    "    Returns:\n",
    "      A MixedUseMLP with parameters set by sampled neurons.\n",
    "    \"\"\"\n",
    "    # Seed for reproducibility\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "        torch.manual_seed(seed)\n",
    "\n",
    "    # Sample PCA latents and invert to full vectors\n",
    "    Z1_new = np.random.multivariate_normal(mu1, cov1, size=M)\n",
    "    neuron1 = pca1.inverse_transform(Z1_new)\n",
    "    Z2_new = np.random.multivariate_normal(mu2, cov2, size=M)\n",
    "    neuron2 = pca2.inverse_transform(Z2_new)\n",
    "\n",
    "    # Split neuron parameter vectors\n",
    "    W1_new = neuron1[:, :n_in]\n",
    "    b1_new = neuron1[:, n_in]\n",
    "    W2_out = neuron1[:, n_in+1:]\n",
    "\n",
    "    W2_in = neuron2[:, :orig_hid]\n",
    "    b2_new = neuron2[:, orig_hid]\n",
    "    W3_out = neuron2[:, orig_hid+1:]\n",
    "\n",
    "    # Build target network\n",
    "    from torch import nn\n",
    "    mlp = MLP(hidden_dim=M, init_type=init_type, seed=seed).to(device)\n",
    "    mlp.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "# np.sqrt(2. / in_dim) \n",
    "        \n",
    "        # Layer1 parameters\n",
    "        # with Kaiming-He dev trick\n",
    "        mlp.fc1.weight.copy_( torch.from_numpy(W1_new).float().to(device) * np.sqrt(2./ n_in) )\n",
    "        mlp.fc1.bias.copy_( torch.from_numpy(b1_new).float().to(device) )\n",
    "\n",
    "        # Layer2 (fc2): build a linking matrix that aligns new outgoing and incoming neuron projections\n",
    "        # We have two sets of vectors:\n",
    "        # 1) W2_out: outgoing projections from new layer1 neurons to old layer2 space ([M, orig_hid])\n",
    "        # 2) W2_in: incoming projections to new layer2 neurons from old layer1 space ([M, orig_hid])\n",
    "        # To construct a full [M, M] weight matrix, we compute an orthonormal basis Q of shape [M, M] via QR,\n",
    "        # then align its first `orig_hid` columns to approximate the W2_out and W2_in jointly.\n",
    "        # Simplest implementation: use random orthonormal Q as a prior that mixes both channels.\n",
    "        \n",
    "        A = torch.randn(M, M, device=device)\n",
    "        Q, Rmat = torch.qr(A)\n",
    "        # ensure proper orientation\n",
    "        if torch.det(Q) < 0:\n",
    "            Q[:, 0] *= -1\n",
    "            \n",
    "        # mlp.fc2.weight.copy_(Q * np.sqrt(2. / M))\n",
    "        # Replace the first `orig_hid` columns of Q with a projection of W2_out and W2_in\n",
    "        \n",
    "        # Project W2_out (M x orig_hid) into M-dimensional basis\n",
    "        proj_out = torch.from_numpy(W2_out).float().to(device) @ Q[:orig_hid, :]  \n",
    "        proj_in  = torch.from_numpy(W2_in).float().to(device) @ Q[:orig_hid, :]\n",
    "        \n",
    "        # Average the two projections for alignment\n",
    "        aligned = 0.5 * (proj_out + proj_in) * np.sqrt(2. / M)\n",
    "        mlp.fc2.weight[:aligned.size(0), :aligned.size(1)].copy_(aligned)\n",
    "        \n",
    "        # Bias for fc2\n",
    "        mlp.fc2.bias.copy_(torch.from_numpy(b2_new).float().to(device))\n",
    "\n",
    "        # Output layer (fc3)\n",
    "        mlp.fc3.weight.copy_(torch.from_numpy(W3_out.T * np.sqrt(2./ M)).float().to(device))\n",
    "        mlp.fc3.bias.zero_()\n",
    "\n",
    "    return mlp\n",
    "\n",
    "def first_epoch_training(model, train_loader, epochs=1):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\n",
    "    hist = []\n",
    "    \n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for data, target in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            hist.append(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "    \n",
    "    return model, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42278b49-a2fa-4fa9-a23b-bc3ac7a662a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 20\n",
    "class_label = 0 # MNIST\n",
    "\n",
    "# 2a) collect\n",
    "L1, L2 = build_distribution(\n",
    "    cfm, n_samples = n_samples, generate_type = class_label\n",
    ")\n",
    "\n",
    "var_accounted = 0.99\n",
    "# 2b) PCA on layer1\n",
    "pca1 = PCA(n_components=var_accounted, whiten=True)\n",
    "Z1   = pca1.fit_transform(L1)\n",
    "mu1  = Z1.mean(axis=0)\n",
    "cov1 = np.cov(Z1, rowvar=False)\n",
    "\n",
    "# 2c) PCA on layer2\n",
    "pca2 = PCA(n_components=var_accounted, whiten=True)\n",
    "Z2   = pca2.fit_transform(L2)\n",
    "mu2  = Z2.mean(axis=0)\n",
    "cov2 = np.cov(Z2, rowvar=False)\n",
    "print(f\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d01197-08ae-4d5f-9483-584c7f1e766b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Z2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4beca0d-8abd-40fe-98c4-a05ee4f90867",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Need to do a loop to sample many cases to test if this is robustly better than Xavier init \n",
    "\n",
    "weird_loader = mnist_test_loader\n",
    "\n",
    "My_M = 64 # random number, more than the original (finicky computer)\n",
    "longshot = build_mixeduse_from_two_pcas(\n",
    "    pca1, mu1, cov1,\n",
    "    pca2, mu2, cov2,\n",
    "    M = My_M,   # desired new hidden size\n",
    "    n_in = 196, n_out = 10, orig_hid = 32,\n",
    "    init_type='xavier', seed=None, device='cpu'\n",
    ")\n",
    "\n",
    "initial_acc = test_mlp(longshot, weird_loader)\n",
    "trained_dumb_recon, recon_hist = first_epoch_training(longshot, weird_loader)\n",
    "print(f\"Populated Model initial performance: {initial_acc:.2f}%\")\n",
    "print(f\"Populated Model After 1 epoch: {test_mlp(trained_dumb_recon, weird_loader):.2f}%\")\n",
    "\n",
    "# new_model = sample_first_mlp_from_batch(dumb)\n",
    "old_model = MLP(hidden_dim = My_M, init_type='xavier', seed=np.random.randint(10))\n",
    "random_acc = test_mlp(old_model, weird_loader)\n",
    "trained_dumb, hist = first_epoch_training(old_model, weird_loader)\n",
    "print(f\"Fresh Initialization initial performance: {random_acc:.2f}%\")\n",
    "print(f\"Fresh Initialization After 1 epoch: {test_mlp(trained_dumb, weird_loader):.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489c0421-87cb-42e9-9a4b-e726af8bc601",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace( 0, len(hist), len(hist))\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "plt.scatter(x, hist, label = f\"Random Initialization\")\n",
    "plt.scatter(x, recon_hist, label = f\"Sampled Initialization\")\n",
    "plt.xlabel(f\"Optimizer Step no. in epoch 1\")\n",
    "plt.ylabel(f\"Loss per step\")\n",
    "plt.legend()\n",
    "# plt.savefig(f\"MLP_Diffusion_figure.png\", format=\"png\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70609a64-da72-455b-a5bb-158d89698791",
   "metadata": {},
   "outputs": [],
   "source": [
    "lil_hist = hist[:50]\n",
    "lil_recon_hist = recon_hist[:50]\n",
    "x = np.linspace( 0, len(lil_hist), len(lil_hist))\n",
    "plt.figure(figsize=(8, 6), dpi=80)\n",
    "plt.scatter(x, lil_hist, label = f\"Random Initialization\")\n",
    "plt.scatter(x, lil_recon_hist, label = f\"Sampled Initialization\")\n",
    "plt.xlabel(f\"Optimizer Step no. in epoch 1\")\n",
    "plt.ylabel(f\"Loss per step\")\n",
    "plt.legend()\n",
    "# plt.savefig(f\"MLP_Diffusion_figure.png\", format=\"png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dae3cb9a-2131-4d53-a033-dcc76f97fd74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
